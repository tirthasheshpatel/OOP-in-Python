{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch > TensorFlow",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirthasheshpatel/OOP-in-Python/blob/master/PyTorch_Premiere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S23tUXpyjRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyUpNZ6yvAZ",
        "colab_type": "code",
        "outputId": "2fbeae44-4aa0-4ce9-d287-b3bd2a42417c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# cannot use np.float32 or np.float64 with torch tensors\n",
        "a = torch.arange(0, 50, step=1, dtype=torch.float64).reshape(10,5)\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "print(a.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n",
            "torch.float64\n",
            "torch.Size([10, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlGbwdpy7n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_style_a = a.numpy() # convert to numpy style array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hc2mbte9SBt",
        "colab_type": "code",
        "outputId": "94a79cd7-d40f-4c9e-b01c-bb455e10023d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "numpy_style_a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.,  2.,  3.,  4.],\n",
              "       [ 5.,  6.,  7.,  8.,  9.],\n",
              "       [10., 11., 12., 13., 14.],\n",
              "       [15., 16., 17., 18., 19.],\n",
              "       [20., 21., 22., 23., 24.],\n",
              "       [25., 26., 27., 28., 29.],\n",
              "       [30., 31., 32., 33., 34.],\n",
              "       [35., 36., 37., 38., 39.],\n",
              "       [40., 41., 42., 43., 44.],\n",
              "       [45., 46., 47., 48., 49.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGzeH30I9T0f",
        "colab_type": "code",
        "outputId": "29d7029f-d0f1-4d14-d58c-9068a9ccf093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# convert numpy to torch style tensor\n",
        "numpy_style_to_torch_style_a = torch.from_numpy(numpy_style_a)\n",
        "print(numpy_style_to_torch_style_a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeyIYvwO91Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.from_numpy(np.random.randn(5, 3)) # Lets generate 2 random tensors\n",
        "b = torch.from_numpy(np.random.randn(3, 5)) # and operate on them"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDh-gTDfvG_V",
        "colab_type": "code",
        "outputId": "56e4a1cb-c8f9-463f-b4fa-a874fde19607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(f\"{a}\\n{b}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5857,  0.5630, -1.7807],\n",
            "        [ 0.1811, -0.5109, -0.0293],\n",
            "        [-0.2274, -0.5476,  0.8134],\n",
            "        [ 0.0467, -2.1368, -0.4759],\n",
            "        [-0.2400,  1.5415, -0.8249]], dtype=torch.float64)\n",
            "tensor([[-0.8948, -0.0917, -1.5818,  0.6531, -1.3392],\n",
            "        [ 0.1832, -0.1612,  0.8322, -0.4541, -0.2946],\n",
            "        [ 2.0112, -0.7415,  0.9092, -1.2129,  1.4463]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5em3PuDJvo0B",
        "colab_type": "code",
        "outputId": "aca89f16-eed9-46f1-e585-4d95bed19355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# to add,subtract use a+b,a-b\n",
        "# for matrix multiplication\n",
        "c = a @ b # @ -> matrix multiplication\n",
        "print(c)\n",
        "c = torch.mm(a, b) # Equivalent to a@b\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.0024,  1.1759, -2.0770,  2.2868, -3.5257],\n",
            "        [-0.3145,  0.0874, -0.7383,  0.3858, -0.1344],\n",
            "        [ 1.7391, -0.4940,  0.6435, -0.8864,  1.6422],\n",
            "        [-1.3903,  0.6930, -2.2848,  1.5779, -0.1213],\n",
            "        [-1.1620,  0.3852,  0.9125,  0.1439, -1.3258]], dtype=torch.float64)\n",
            "tensor([[-4.0024,  1.1759, -2.0770,  2.2868, -3.5257],\n",
            "        [-0.3145,  0.0874, -0.7383,  0.3858, -0.1344],\n",
            "        [ 1.7391, -0.4940,  0.6435, -0.8864,  1.6422],\n",
            "        [-1.3903,  0.6930, -2.2848,  1.5779, -0.1213],\n",
            "        [-1.1620,  0.3852,  0.9125,  0.1439, -1.3258]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYgzjKazwKCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making tensors on GPU :o\n",
        "# See the RAM bar will increase as soon as we create a tensor on GPU\n",
        "a_gpu = torch.arange(0, 50, dtype=torch.float64, device='cuda').reshape(5, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnfNts_LwtHs",
        "colab_type": "code",
        "outputId": "2e16f5cb-5a40-474a-d9ca-2b9ed1aef03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "a_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
              "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
              "        [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
              "        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai1YLLfDWevW",
        "colab_type": "code",
        "outputId": "0b25c267-691b-4712-eb62-3b6b09e9b9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.is_tensor\n",
        "print(torch.is_tensor([1., 2., 3.]))\n",
        "print(torch.is_tensor(a))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbFnvrpOWwyg",
        "colab_type": "code",
        "outputId": "8583ac6f-5687-4a17-ec60-8f1eae905d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.set_default_dtype -> set floating point dtype\n",
        "torch.set_default_dtype(torch.float64)\n",
        "a = torch.linspace(0, 10, 100)\n",
        "print(a.dtype)\n",
        "# torch.get_default_dtype\n",
        "print(torch.get_default_dtype())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float64\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawr4hAyXANn",
        "colab_type": "code",
        "outputId": "163a81cd-5c8a-45d7-c4e5-e8555a691fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.numel -> same as np.ndarray.size\n",
        "print(torch.numel(a))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42PEyCm-YG-I",
        "colab_type": "code",
        "outputId": "7f5fee3d-995b-4da6-9199-170e651b4378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# torch.tensor -> Similar to np.array(data)\n",
        "# ``torch.tensor`` always copies ``data``. To avoid copying\n",
        "# np.ndarray use ``torch.as_tensor`` instead\n",
        "a = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda')\n",
        "print(a)\n",
        "\n",
        "# You can also record gradients on the\n",
        "# operations invloving `a` by setting require_grad=True\n",
        "a = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], device='cuda', requires_grad=True)\n",
        "b = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda', requires_grad=True)\n",
        "# Operate on a and b\n",
        "c = (a @ b).sum()\n",
        "# The graph formed is:\n",
        "# a     b\n",
        "#  \\   /\n",
        "#    c (op: SumBackward)\n",
        "print(c.grad_fn)\n",
        "print(c.backward()) # This just calculates the gradient of c wrt all the nodes in the graph\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n",
            "<SumBackward0 object at 0x7f981d7577b8>\n",
            "None\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n",
            "tensor([[12., 12., 12.],\n",
            "        [15., 15., 15.],\n",
            "        [18., 18., 18.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf5j6K-2Yz1b",
        "colab_type": "code",
        "outputId": "66a747a3-97fb-4c18-ca3a-cf659c0eed27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.sparse_coo_tensor -> create a sparse tensor ==> amazing\n",
        "a = torch.sparse_coo_tensor(torch.empty([1, 0]),\n",
        "                            torch.empty([0, 2]), [1, 2])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(indices=tensor([], size=(1, 0)),\n",
            "       values=tensor([], size=(0, 2)),\n",
            "       size=(1, 2), nnz=0, layout=torch.sparse_coo)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Ril3Lbus7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.as_tensor  -> create a tensor from np.ndarray\n",
        "# torch.as_strided -> np.lib.stride_tricks.as_strided\n",
        "# torch.from_numpy -> as the name suggest\n",
        "# torch.zeros\n",
        "# torch.zeros_like\n",
        "# torch.ones\n",
        "# torch.ones_like\n",
        "# torch.empty\n",
        "# torch.empty_like\n",
        "# torch.full\n",
        "# torch.full_like\n",
        "# torch.arange\n",
        "# torch.linspace\n",
        "# torch.logspace\n",
        "# torch.eye\n",
        "# torch.empty_strided\n",
        "# torch.cat -> np.concatenate\n",
        "# torch.chunk -> Splits a tensor into a specific number of chunks.\n",
        "#                Each chunk is a view of the input tensor\n",
        "# torch.reshape\n",
        "# torch.stack\n",
        "# torch.t -> same as np.ndarray.T ==> Use `torch.tensor.T` instead\n",
        "# torch.transpose\n",
        "# torch.take -> same as np.take\n",
        "# torch.where -> same as np.where"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4mOdnd7nd_",
        "colab_type": "code",
        "outputId": "a3687346-13fa-436a-fb1b-165ce1948bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.gather -> Gathers values along an axis specified by `dim` (`axis`)\n",
        "a = torch.arange(10)\n",
        "a_gather = torch.gather(a, dim=0, index=torch.tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7]))\n",
        "print(a_gather)\n",
        "t = torch.tensor([[1,2],[3,4]])\n",
        "print(torch.gather(t, 1, torch.tensor([[0,0],[1,0]])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7])\n",
            "tensor([[1, 1],\n",
            "        [4, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plc3ACy5-7w5",
        "colab_type": "code",
        "outputId": "9fc5e7a9-d917-4be5-dd57-55ee2cfa364c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.index_seelct -> select the indices along a given `dim` (`axis`)\n",
        "# This operation creates a copy if the `out` argument is not the same shape\n",
        "# as the input tensor.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.index_select(a, 0, torch.tensor([0, 2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.4594,  0.2898, -0.7687,  1.1532],\n",
            "        [-0.5660, -0.5339,  1.4297, -0.0780],\n",
            "        [ 1.0289, -0.7272,  1.8765,  0.3879]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4594,  0.2898, -0.7687,  1.1532],\n",
              "        [ 1.0289, -0.7272,  1.8765,  0.3879]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv24xIn4-9an",
        "colab_type": "code",
        "outputId": "8eeb5902-f92d-42d9-ac93-bcfbee689f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# torch.masked_select -> selects the masked entries only.\n",
        "# Always creates a copy.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.masked_select(a, a<=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2863,  0.3866, -1.8093, -2.9834],\n",
            "        [-1.7142,  0.0790, -0.9346,  0.9550],\n",
            "        [-1.4393,  1.3298, -0.7261, -0.3710]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.8093, -2.9834, -1.7142, -0.9346, -1.4393, -0.7261, -0.3710])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCg9vWLj_ogQ",
        "colab_type": "code",
        "outputId": "2ce27aee-7ea6-4d18-ec55-c7831bb40b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.narrow -> Select the entires from the array\n",
        "# along a particular `dim` starting at `start` and\n",
        "# ending at `end`. Signature: input, dim, start, end.\n",
        "# Its a view, not a copy\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.narrow(a, 0, 1, 2) # 2 inclusive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2850,  0.4749,  1.9929, -0.6216],\n",
            "        [ 1.6201, -2.2011, -0.7496, -0.1550],\n",
            "        [-0.4795, -0.9549, -0.4398, -0.7526]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.6201, -2.2011, -0.7496, -0.1550],\n",
              "        [-0.4795, -0.9549, -0.4398, -0.7526]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMwjAh7NAwWc",
        "colab_type": "code",
        "outputId": "213f0e83-bb69-4327-d3bf-b84363dc2fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.reshape -> Creates a view whenever possible\n",
        "# use torch.as_strided for garunteed view.\n",
        "a = torch.randn(1, 2, 3, 4, 5)\n",
        "print(a.shape)\n",
        "torch.reshape(a, [5, 4, 3, 2, 1]).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3, 4, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsLVv5uEB6Kp",
        "colab_type": "code",
        "outputId": "136422e7-f546-4f77-de4d-60cae33882ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# torch.split -> Splits the tensor into chunks.\n",
        "# Each chunk is a view of the original tensor.\n",
        "a = torch.randn(3, 5)\n",
        "print(a)\n",
        "print(torch.split(a, [1, 4], dim=1)[0])\n",
        "print(torch.split(a, [1, 4], dim=1)[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6687,  1.0434,  0.1391,  1.3075, -0.8829],\n",
            "        [-0.3051,  0.8685,  0.1271, -0.0328,  0.8895],\n",
            "        [ 0.4830, -1.0533,  0.1713, -0.2185, -1.1297]])\n",
            "tensor([[-0.6687],\n",
            "        [-0.3051],\n",
            "        [ 0.4830]])\n",
            "tensor([[ 1.0434,  0.1391,  1.3075, -0.8829],\n",
            "        [ 0.8685,  0.1271, -0.0328,  0.8895],\n",
            "        [-1.0533,  0.1713, -0.2185, -1.1297]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueS1jnC-DTio",
        "colab_type": "code",
        "outputId": "5f94f286-682d-4c54-b387-9c4ca88e5943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.squeeze -> same as np.squeeze\n",
        "a = torch.randn(5, 1, 1, 4, 1, 1, 3, 1, 1, 2)\n",
        "print(a.shape)\n",
        "b = torch.squeeze(a)\n",
        "print(b.shape)\n",
        "# torch.unsqueeze -> wow!\n",
        "torch.unsqueeze(b, -1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 1, 4, 1, 1, 3, 1, 1, 2])\n",
            "torch.Size([5, 4, 3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bd_jd2BEldK",
        "colab_type": "code",
        "outputId": "d18daddf-52f3-4b31-dce0-32d90a26aa3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.where -> if `condition`, `x`, else `y`\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.where(a>2, a, 1-a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, -1],\n",
              "        [ 3,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63mbiDnHRzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                       Random Sampling in Torch!!\n",
        "# torch.seed\n",
        "# torch.set_rng_state\n",
        "# torch.get_rng_state\n",
        "# torch.rand\n",
        "# torch.rand_like\n",
        "# torch.randint\n",
        "# torch.randint_like\n",
        "# torch.randn\n",
        "# torch.randn_like\n",
        "# torch.randperm -> Returns a random permutation of integers from `0` to `n-1`.\n",
        "# torch.bernoulli\n",
        "# torch.multinomial\n",
        "# torch.poisson\n",
        "# torch.normal\n",
        "\n",
        "#                       Inplace Random Sampling\n",
        "# =========================     =========================================================\n",
        "#         CODE                                         DOCUMENTATION\n",
        "# =========================     =========================================================\n",
        "# torch.Tensor.bernoulli_()   - in-place version of torch.bernoulli()\n",
        "# torch.Tensor.cauchy_()      - numbers drawn from the Cauchy distribution\n",
        "# torch.Tensor.exponential_() - numbers drawn from the exponential distribution\n",
        "# torch.Tensor.geometric_()   - elements drawn from the geometric distribution\n",
        "# torch.Tensor.log_normal_()  - samples from the log-normal distribution\n",
        "# torch.Tensor.normal_()      - in-place version of torch.normal()\n",
        "# torch.Tensor.random_()      - numbers sampled from the discrete uniform distribution\n",
        "# torch.Tensor.uniform_()     - numbers sampled from the continuous uniform distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikteJICdIOAq",
        "colab_type": "code",
        "outputId": "53602597-4e5e-4eb3-f4b9-1185c9b562bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Serialization\n",
        "# torch.save -> Saves tensor objects and model in pickle file\n",
        "# torch.load -> Loads tensor objects and model from a pickle file\n",
        "a = torch.arange(10)\n",
        "torch.save(a, 'torch_tensor_a.pkl')\n",
        "a = torch.load('torch_tensor_a.pkl')\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcyTevew_7y2",
        "colab_type": "code",
        "outputId": "07d4e8d8-2b4c-4644-d0a2-2c5ccfc2e807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Parallelism\n",
        "# torch.get_num_threads()\n",
        "# torch.set_num_threads()\n",
        "# torch.get_num_inteop_threads()\n",
        "# torch.set_num_interop_threads()\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(4)\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(1)\n",
        "print(torch.get_num_threads())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "4\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfy6fkaAAiF",
        "colab_type": "code",
        "outputId": "72d23ae6-74cf-4b6a-f772-24864ed226ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.no_grad() -> Context manager to disable backprop for\n",
        "#                    some particular operation. This means that\n",
        "#                    the operation will not be recorded on graph.\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    c = a * b\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEbwIIhBiHz",
        "colab_type": "code",
        "outputId": "b72968aa-5dac-4c0a-8421-dfc45c878877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.enable_grad() -> Enablewe grad for operations where grad computation\n",
        "#                        has been altered using torch.no_grad or torch.set_grad_enabled\n",
        "# Method 1\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    with torch.enable_grad():\n",
        "        c = a * b\n",
        "print(c.requires_grad)\n",
        "\n",
        "# Method 2\n",
        "@torch.enable_grad()\n",
        "def mul_op(x, y):\n",
        "    return x * y\n",
        "\n",
        "with torch.no_grad():\n",
        "    c = mul_op(a, b)\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slupOmQCbj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Math operations\n",
        "# torch.abs\n",
        "# torch.acos\n",
        "# torch.asin\n",
        "# torch.atan\n",
        "# torch.atan2\n",
        "# torch.sin\n",
        "# torch.cos\n",
        "# torch.cosh\n",
        "# torch.tanh\n",
        "# torch.sinh\n",
        "# torch.tan\n",
        "# torch.exp\n",
        "# torch.log\n",
        "# torch.log10\n",
        "# torch.log2\n",
        "# torch.pow\n",
        "# torch.div\n",
        "# torch.add\n",
        "# torch.mul\n",
        "# torch.reciprocal\n",
        "# torch.remainder\n",
        "# torch.round\n",
        "# torch.rsqrt\n",
        "# torch.sqrt\n",
        "# torch.sigmoid\n",
        "# torch.sign\n",
        "# torch.square\n",
        "# torch.true_devide\n",
        "# torch.trunc -> truncate a floting point into integer\n",
        "# torch.argmax\n",
        "# torch.argmin\n",
        "# torch.max\n",
        "# torch.min\n",
        "# torch.dist -> Computes the p-norm of a tensor (default p=2)\n",
        "# torch.logsumexp\n",
        "# torch.mean\n",
        "# torch.median\n",
        "# torch.mode\n",
        "# torch.std\n",
        "# torch.std_mean\n",
        "# torch.var\n",
        "# torch.var_mean\n",
        "# torch.sum\n",
        "# torch.prod\n",
        "# torch.cumsum\n",
        "# torch.cumprod\n",
        "# torch.unique\n",
        "# torch.diag -> same as np.diag\n",
        "# torch.cholesky\n",
        "# torch.cholesky_solve\n",
        "# torch.solve\n",
        "# torch.triangular_solve\n",
        "# torch.lu\n",
        "# torch.lu_solve\n",
        "# torch.qr\n",
        "# torch.svd\n",
        "# torch.scd_lowrank\n",
        "# torch.pca_lowrank\n",
        "# torch.symeig -> Eigenvalues and vectors for symetric matrices\n",
        "# torch.matrix_power\n",
        "# torch.matrix_rank\n",
        "# torch.eig\n",
        "# torch.det\n",
        "# torch.logdet\n",
        "# torch.slogdet\n",
        "# torch.trace\n",
        "# torch.tril -> Returns the lower triangular part of input\n",
        "# torch.triu\n",
        "# torch.lstsq\n",
        "# torch.inverse  -> same as np.inv\n",
        "# torch.pinverse -> same as np.pinv\n",
        "# torch.flatten\n",
        "# torch.norm -> Computes the norm of a matrix or vector\n",
        "# torch.add -> Can be used as axpy but for tensors\n",
        "# torch.addcdiv -> Performs the element-wise division of `tensor1` by `tensor2`,\n",
        "#                  multiply the result by the scalar `value` and add it to `input`\n",
        "#                  result = input + value * (tensor1 / tensor2)\n",
        "# torch.addcmul -> Same as addcdiv but for multiplecation\n",
        "# torch.bitwise_not -> oeprator |\n",
        "# torch.bitwise_and -> operator &\n",
        "# torch.bitwise_not\n",
        "# torch.bitwise_xor\n",
        "# torch.ceil\n",
        "# torch.floor\n",
        "# torch.angle -> Commutes the angle of each vector (complex number function)\n",
        "# torch.conj -> Computes the conjugate of each vector (complex number function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tADWFzJiF4LZ",
        "colab_type": "code",
        "outputId": "0061e7e8-b277-4695-9ae8-97e89da06bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# torch.clamp -> works like `np.clip`. Clips a tensor in [min, max] range\n",
        "a = torch.arange(0, 20)\n",
        "print(a)\n",
        "a = torch.clamp(a, min=5, max=15)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "tensor([ 5,  5,  5,  5,  5,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
            "        15, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CQEJfsoIRM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Advanced Mathematical Operations\n",
        "# torch.digamma -> Derivative of log of gamma function => d/dx ( ln(gamma(input)) )\n",
        "# torch.erf -> Error function\n",
        "# torch.erfc -> Complement of the error function\n",
        "# torch.erfinv -> Inverse of the error function\n",
        "# torch.exp\n",
        "# torch.expm1\n",
        "# torch.log1p -> inverse of torch.expm1\n",
        "# torch.floor_devide\n",
        "# torch.fmod -> Float %\n",
        "# torch.frac -> Computes the fractional portion of each element in `input`\n",
        "# torch.lerp -> out = start + weight * (end - start)\n",
        "# torch.lgamma -> Logirithm of the gamma function\n",
        "# torch.mvlgamma -> Compute the multivariate log gamma function\n",
        "# torch.polygamma -> Compute the n'th derivative of `torch.digamma` function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAti9avJivi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparison Ops\n",
        "# torch.equal\n",
        "# torch.eq\n",
        "# torch.ne\n",
        "# torch.ge\n",
        "# torch.le\n",
        "# torch.gt\n",
        "# torch.lt\n",
        "# torch.allclose\n",
        "# torch.isfinite\n",
        "# torch.isinf\n",
        "# torch.isnan\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgrPg-5S7rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.sort\n",
        "# torch.argsort\n",
        "# torch.topk\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEISpvkXfnrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: BLAS and LAPACK functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XURzQke-fr0-",
        "colab_type": "code",
        "outputId": "40e7e8eb-27fd-4edb-ba05-d256b25f897d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "#                           NEURAL NETWORKS IN PYTORCH                          #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "torch.set_default_dtype(torch.float32)\n",
        "torch.manual_seed(420)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f97d4d3f070>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDg8dEpiG7t",
        "colab_type": "code",
        "outputId": "833d9f19-f9e5-431f-9596-f99aa0d9053d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# torch.nn.Parameter -> Registers a parameter in the scope of the module.\n",
        "#                       Doesn't backpropogate if used in or from other module,\n",
        "#                       unless registered.\n",
        "a = torch.randn(4, 5)\n",
        "print(a)\n",
        "nn.Parameter(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0070,  0.5044,  0.6704, -0.3829,  0.0938],\n",
            "        [-2.0492,  1.0550, -0.6222,  0.5020,  0.7538],\n",
            "        [ 0.6128, -0.9300,  1.3646, -0.7372, -0.7084],\n",
            "        [-0.2842, -1.4816,  0.3298,  0.4856,  0.4131]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0070,  0.5044,  0.6704, -0.3829,  0.0938],\n",
              "        [-2.0492,  1.0550, -0.6222,  0.5020,  0.7538],\n",
              "        [ 0.6128, -0.9300,  1.3646, -0.7372, -0.7084],\n",
              "        [-0.2842, -1.4816,  0.3298,  0.4856,  0.4131]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXW5LTQfiW-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.Module -> A class to create your NN. Define `__init__` to\n",
        "#                    initialize model parameters and `forward` method\n",
        "#                    to define operations on the parameters and input.\n",
        "#                    Registered parameters will be backpropogated while\n",
        "#                    training.\n",
        "class LinearRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LinearRegressor, self).__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_features, 1))\n",
        "        self.b = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.w + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9XskQqioFbA",
        "colab_type": "code",
        "outputId": "ed4af3c9-a0f7-4941-ec4c-9cf4498daea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Preparing Data\n",
        "import matplotlib.pyplot as plt\n",
        "n_examples = 10\n",
        "n_features = 1\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "y_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "plt.scatter(X, y_true)\n",
        "plt.title('Generated Data')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7y2XJ7BlOjG",
        "colab_type": "code",
        "outputId": "606b5e37-362d-41d3-970d-df028facaf5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Initialize the LinearRegressor model.\n",
        "model = LinearRegressor(n_features)\n",
        "print(model(X))\n",
        "# .parameters() `yields` the parameters.\n",
        "# Not a list of parameters.\n",
        "print([i for i in model.parameters()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9310],\n",
            "        [ 0.0286],\n",
            "        [ 1.1748],\n",
            "        [ 0.5521],\n",
            "        [ 0.4158],\n",
            "        [-2.0681],\n",
            "        [ 0.3057],\n",
            "        [-0.5863],\n",
            "        [-0.1718],\n",
            "        [-1.4015]], grad_fn=<AddBackward0>)\n",
            "[Parameter containing:\n",
            "tensor([[-0.8565]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0513], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr4CTh9SnKLM",
        "colab_type": "code",
        "outputId": "4d0a78ae-0629-4f73-c849-477ba87234e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training a torch.nn.Module() model\n",
        "from time import sleep\n",
        "from sys import stdout\n",
        "epochs = 100\n",
        "# torch.nn contains many loss functions. We use\n",
        "# mse loss with mean over all the examples.\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "# torch.optim contains many optimizers like Adam, Momentum\n",
        "# SGD, Adagrad, Adadelta, RMSProp, Nesterov Momentum, etc\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_pred = model(X) # Compute the prediction by forward propogating\n",
        "\n",
        "    loss = loss_fn(y_pred, y_true) # Evaluate the loss function\n",
        "    # Print the loss\n",
        "    stdout.write(f'\\repoch: {i} \\t {20*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f}')\n",
        "    optimizer.zero_grad() # Initialize the optimizer\n",
        "    # Backpropogate through the graph. This will compute the\n",
        "    # gradients of all the parameters in-place and store them\n",
        "    # in .grad() method of the parameters.\n",
        "    loss.backward()\n",
        "    optimizer.step() # Take one step of optimizer. This will update our parameters.\n",
        "    sleep(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.017"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06D8Kj1Qp2uY",
        "colab_type": "code",
        "outputId": "416d1b43-1c6f-40b2-ee26-6224d842fc74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Let's see how good did we perform\n",
        "print(w_true)\n",
        "print(b_true)\n",
        "params = [i for i in model.parameters()]\n",
        "print(params[0])\n",
        "print(params[1])\n",
        "print(y_true)\n",
        "print(model(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5441]])\n",
            "tensor([0.5470])\n",
            "Parameter containing:\n",
            "tensor([[0.4573]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.5397], requires_grad=True)\n",
            "tensor([[ 1.1738],\n",
            "        [ 0.6697],\n",
            "        [-0.1860],\n",
            "        [ 0.2040],\n",
            "        [ 0.2006],\n",
            "        [ 1.8688],\n",
            "        [ 0.2579],\n",
            "        [ 0.8006],\n",
            "        [ 0.5921],\n",
            "        [ 1.4782]])\n",
            "tensor([[ 1.0641],\n",
            "        [ 0.5518],\n",
            "        [-0.0602],\n",
            "        [ 0.2723],\n",
            "        [ 0.3451],\n",
            "        [ 1.6712],\n",
            "        [ 0.4039],\n",
            "        [ 0.8801],\n",
            "        [ 0.6588],\n",
            "        [ 1.3153]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f9VmRAQq3O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Somethings to remember about torch.nn.Module()\n",
        "# ============================================================================================= #\n",
        "#                                      Some Methods to remember                                 #\n",
        "# ============================================================================================= #\n",
        "# add_module(name, module) -> Add a sub module that will be registered\n",
        "#                             and affected by changes to the main module\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# apply(fn) -> Apply a function to all the submodules and the main module\n",
        "#              The function `fn` takes a module `m` as an argument\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# children() -> Generator of the children of the model (generates only the module)\n",
        "# named_children() -> Generator of the children of the model (generates the module and its name)\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# modules() -> Generates the modules in the scope of the main module\n",
        "# named_modules() -> Generates name along wwith module\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# parameters() -> Generator of the parameters in the main and sub modules\n",
        "# named_parameters() -> Generates name along with their object\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# cpu()   -> Move all parameters and buffers to cpu\n",
        "# cuda()  -> Move all parameters and buffers to gpu\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# double() -> Casts all the parameters/buffers to double (float64) datatype\n",
        "# float()  -> Casts all the parameters/buffers to float (float32) datatype\n",
        "# half()   -> Casts all the parameters/buffers to half datatype\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# extra_repr() -> Sets the extra representation of the module to print custom info\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# register_forward_hook(hook) -> Registers a forward hook on the module.\n",
        "#                                The hook will be called every time after forward()\n",
        "#                                has computed an output.\n",
        "#                                It should have the signature hook(module, input, output)\n",
        "# register_forward_pre_hood(hook) -> Called before the call to forward(). Must have signature\n",
        "#                                    hook(module, input) -> None or modified input.\n",
        "# register_parameter(name, tensor) -> Register a parameter in a module so the gradients will be\n",
        "#                                     propogated when backward is called.\n",
        "# requires_grad_() -> Used to finetune models. Setting it false disables the backprob state of\n",
        "#                     parameters with which it is called. You can finetune models be disabling\n",
        "#                     some gradients.\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# to() -> See the docs to understand it properly.\n",
        "# ============================================================================================= #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvIIXgWQNvRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An example of `add_module`\n",
        "class LogisticRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticRegressor, self).__init__()\n",
        "        self.add_module('lm', LinearRegressor(n_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.lm(X)\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57PH7CIOwsp",
        "colab_type": "code",
        "outputId": "46fb355f-f5c9-40b2-94cc-b264ce9ccff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Let's see how `add_module` works\n",
        "model = LogisticRegressor(n_features)\n",
        "model(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3267],\n",
              "        [0.3550],\n",
              "        [0.3900],\n",
              "        [0.3708],\n",
              "        [0.3666],\n",
              "        [0.2949],\n",
              "        [0.3633],\n",
              "        [0.3367],\n",
              "        [0.3490],\n",
              "        [0.3133]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONgsz7Y1O00j",
        "colab_type": "code",
        "outputId": "6035ff58-71d1-4bd0-adc5-676dd0a4c8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Example of `children` method\n",
        "list(model.children())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LinearRegressor()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXk55XmO3Pv",
        "colab_type": "code",
        "outputId": "ba76b2c8-5973-42ad-9501-83aad88228dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Example of torch.apply\n",
        "@torch.no_grad()\n",
        "def apply_func(m):\n",
        "    # m is a module so we can preprocess\n",
        "    # parameters if we want to.\n",
        "    m.w = nn.Parameter(torch.tensor([[1.], [2.], [3.], [4.]]))\n",
        "    m.b = nn.Parameter(torch.tensor([1.]))\n",
        "\n",
        "model.apply(apply_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressor(\n",
              "  (lm): LinearRegressor()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnenQlDMQi_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some special modules\n",
        "# 1. torch.nn.Sequential -> A sequential model\n",
        "# 2. torch.nn.ModuleList -> Module with multiple sub-modules passed as a list\n",
        "# 3. torch.nn.ModuleDict -> Module with multiple sub-modules passed as a ordered dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxwGZqcDb-hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================================= #\n",
        "#                                       Models! Models! Models!                                 #\n",
        "# ============================================================================================= #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AEA7bIJcz36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################\n",
        "#   1. Linear Regression   #\n",
        "############################\n",
        "n_examples = 10\n",
        "n_features = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGFG_F-chH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Define Model\n",
        "class LinearRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LinearRegressor, self).__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_features, 1))\n",
        "        self.b = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.w + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqRH1Psvc_PX",
        "colab_type": "code",
        "outputId": "aaead666-df39-4bd2-bc8c-b7f5c453b978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Step 2: Prepare Data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "\n",
        "y_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "\n",
        "if n_features == 1:\n",
        "    plt.scatter(X, y_true)\n",
        "    plt.title('Generated Data')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVQW284YdVhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Initialize the LinearRegressor model.\n",
        "model = LinearRegressor(n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woR3BGyldfHr",
        "colab_type": "code",
        "outputId": "6fe804ad-a807-4fe2-e688-4b734e025045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {20*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.024"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxMGs0Bvd-jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "#   1. Logistic Regression   #\n",
        "##############################\n",
        "n_examples = 10\n",
        "n_features = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHl1NA7zd0cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Define Model\n",
        "class LogisticRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticRegressor, self).__init__()\n",
        "        self.add_module('lm', LinearRegressor(n_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.lm(X)\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jspJmUyeJPv",
        "colab_type": "code",
        "outputId": "7136356c-3141-4637-f1b4-b07de57d1982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Step 2: Prepare Data\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "\n",
        "f_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "y_true = 1.*(torch.sigmoid(f_true) >= 0.5)\n",
        "\n",
        "if n_features == 1:\n",
        "    plt.scatter(X, y_true)\n",
        "    plt.title('Generated Data')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5JEk6Cyec72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Initialize the LogisticRegressor model.\n",
        "model = LogisticRegressor(n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "derj8X0Dey1V",
        "colab_type": "code",
        "outputId": "bad2979e-2203-4b61-e3d2-2a709fb1bede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 100\n",
        "\n",
        "loss_fn   = nn.BCELoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_proba = model(X)\n",
        "    y_pred  = 1.*(y_proba >= 0.5)\n",
        "    loss = loss_fn(y_proba, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {30*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f} \\t'\n",
        "                 f' acc: {torch.sum(y_pred == y_true) / float(n_examples):.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.576 \t acc: 0.600"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsQNWYmugWo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   1. ANN   #\n",
        "##############\n",
        "n_examples = 100\n",
        "n_features = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BHXYVSciSJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We complete steps 1 and 3 in one step by using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPA99jdCjJcG",
        "colab_type": "code",
        "outputId": "7c5fcc41-f1aa-4508-c9f9-ba08b80bc023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's peek into the model and see its parameters.\n",
        "dict(model.named_parameters()).keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['0.weight', '0.bias', '2.weight', '2.bias', '4.weight', '4.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVm3NrEqjLIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Prepare data\n",
        "X = torch.randn(n_examples, n_features)\n",
        "f_true = (torch.logsumexp(X, dim=1, keepdim=True) +\n",
        "          0.01*torch.randn(n_examples, 1))\n",
        "f_true = torch.sigmoid(f_true-f_true.mean())\n",
        "y_true = 1.*(f_true >= 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7PJ-Hrek7xt",
        "colab_type": "code",
        "outputId": "1fd0647a-f267-42b3-a100-c506051f87ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    f_pred = model(X)\n",
        "    y_pred  = 1.*(torch.sigmoid(f_pred) >= 0.5)\n",
        "    loss = loss_fn(f_pred, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {30*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f} \\t'\n",
        "                 f' acc: {torch.sum(y_pred == y_true) / float(n_examples):.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 19 \t loss: 0.051 \t acc: 0.990"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP6_YGSvk81h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   1. CNN   #\n",
        "##############\n",
        "torch.set_default_dtype(torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ0UPmam4nEA",
        "colab_type": "code",
        "outputId": "499c5f81-0c5a-4ed7-b8aa-39ce09b74e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train / 255.).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_test = (x_test / 255.).reshape(-1, 1, 28, 28).astype('float32')\n",
        "y_train, y_test = ((y_train).astype('float32'),\n",
        "                   (y_test).astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCgazCqb4vMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = (torch.as_tensor(x_train, device='cuda'),\n",
        "                                    torch.as_tensor(x_test, device='cuda'),\n",
        "                                    torch.as_tensor(y_train, device='cuda'),\n",
        "                                    torch.as_tensor(y_test, device='cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE8A--vk5UNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "model = nn.Sequential(OrderedDict(\n",
        "    [('conv_layer_1'   , nn.Conv2d(1, 16, 3, 1)),    # 16 x 26 x 26\n",
        "     ('relu_1'         , nn.ReLU()),\n",
        "     ('conv_layer_2'   , nn.Conv2d(16, 32, 3, 1)),   # 32 x 24 x 24\n",
        "     ('relu_2'         , nn.ReLU()),\n",
        "     ('maxpool_layer_1', nn.MaxPool2d(2, stride=2)), # 32 x 12 x 12\n",
        "     ('conv_layer_3'   , nn.Conv2d(32, 64, 3, 1)),   # 64 x 10 x 10\n",
        "     ('relu_3'         , nn.ReLU()),                 #     |\n",
        "     ('flatten_layer'  , nn.Flatten()),              #     |\n",
        "     ('linear_layer_1' , nn.Linear(64*10*10, 64)),   # <----\n",
        "     ('relu_4'         , nn.ReLU()),\n",
        "     ('linear_layer_2' , nn.Linear(64, 32)),\n",
        "     ('relu_5'         , nn.ReLU()),\n",
        "     ('out_layer'      , nn.Linear(32, 10))]\n",
        "))\n",
        "model = model.to(torch.device('cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzQAEu0t7DUI",
        "colab_type": "code",
        "outputId": "d43dbf1b-76a2-4cd7-e8a4-b409376be4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 10\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "    for idx in range(x_train.shape[0] // batch_size):\n",
        "        # Get the batch to train\n",
        "        x_batch = x_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "        y_batch = y_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "\n",
        "        # Forward pass\n",
        "        f_pred = model(x_batch)\n",
        "        y_pred = nn.functional.softmax(f_pred, dim=1)\n",
        "        loss = loss_fn(f_pred, y_batch.long())\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the results\n",
        "        stdout.write(f'\\r epoch : {i}\\t'\n",
        "                     f'step : {min((idx+1)*batch_size, x_train.shape[0])}/{x_train.shape[0]}\\t'\n",
        "                     f'loss : {loss.item():.3f}\\t'\n",
        "                     f'accuracy : {torch.sum(1.*(y_pred.argmax(axis=1) == y_batch)) / y_batch.shape[0]:.3f}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch : 0\tstep : 60000/60000\tloss : 0.275\taccuracy : 0.929\n",
            " epoch : 1\tstep : 60000/60000\tloss : 0.160\taccuracy : 0.960\n",
            " epoch : 2\tstep : 60000/60000\tloss : 0.110\taccuracy : 0.976\n",
            " epoch : 3\tstep : 60000/60000\tloss : 0.082\taccuracy : 0.985\n",
            " epoch : 4\tstep : 60000/60000\tloss : 0.069\taccuracy : 0.989\n",
            " epoch : 5\tstep : 60000/60000\tloss : 0.059\taccuracy : 0.991\n",
            " epoch : 6\tstep : 60000/60000\tloss : 0.053\taccuracy : 0.990\n",
            " epoch : 7\tstep : 60000/60000\tloss : 0.047\taccuracy : 0.991\n",
            " epoch : 8\tstep : 60000/60000\tloss : 0.045\taccuracy : 0.992\n",
            " epoch : 9\tstep : 60000/60000\tloss : 0.040\taccuracy : 0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDd-qXCo7xV8",
        "colab_type": "code",
        "outputId": "7272d7c0-a865-4d33-f596-98eeba5b438f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_probs_test = model(x_test)\n",
        "y_preds_test = y_probs_test.argmax(axis=1)\n",
        "print(f\"Test set accuracy : {torch.sum(1.*(y_preds_test == y_test)) / y_test.shape[0]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy : 0.9872999787330627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0IxZFl5r0vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "#   4. Autoencoder   #\n",
        "######################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLgzycPIuDgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Prepare data\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = (1.*((x_train / 255.)>=0.5)).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_test = (1.*((x_test / 255.)>=0.5)).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_train, x_test = (torch.as_tensor(x_train, device='cuda'),\n",
        "                   torch.as_tensor(x_test, device='cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtZfMzcGuhjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 and 3\n",
        "from functools import partial\n",
        "#  IPReLU => inplace relu\n",
        "IPReLU = partial(nn.ReLU, True)\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, X, *args, **kwargs):\n",
        "        return X.view(-1, *self.shape)\n",
        "\n",
        "encoder = nn.Sequential(OrderedDict([\n",
        "        ('e_conv_layer_1', nn.Conv2d(1, 16, 5, 1)),               # 16 x 24 x 24\n",
        "        ('e_relu_layer_1', IPReLU()),\n",
        "        ('e_conv_layer_2', nn.Conv2d(16, 32, 5, 1)),              # 32 x 20 x 20\n",
        "        ('e_relu_layer_2', IPReLU()),\n",
        "        ('e_max_pool_layer_1', nn.MaxPool2d(2, 2)),               # 32 x 10 x 10\n",
        "        ('e_conv_layer_3', nn.Conv2d(32, 64, 5, 1)),              # 64 x 6 x 6\n",
        "        ('e_relu_layer_3', IPReLU()),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.75)),\n",
        "        ('e_conv_layer_4', nn.Conv2d(64, 128, 5, 1)),             # 128 x 2 x 2\n",
        "        ('e_relu_layer_4', IPReLU()),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.85)),\n",
        "        ('e_flatten_layer', nn.Flatten()),\n",
        "        ('e_linear_layer_1', nn.Linear(128*2*2, 64))              # 64 ==> Bottleneck\n",
        "]))\n",
        "\n",
        "decoder = nn.Sequential(OrderedDict([\n",
        "        ('inv_linear_layer_1', nn.Linear(64, 128*2*2)),           # 128 * 2 * 2\n",
        "        ('inv_relu_layer_4', IPReLU()),\n",
        "        ('inv_flatten_layer', Reshape(128, 2, 2)),                # 128 x 2 x 2\n",
        "        ('inv_conv_layer_4', nn.ConvTranspose2d(128, 64, 5, 1)),  # 64 x 6 x 6\n",
        "        ('inv_relu_layer_3', IPReLU()),\n",
        "        ('inv_conv_layer_3', nn.ConvTranspose2d(64, 32, 5, 1)),   # 32 x 10 x 10\n",
        "        ('inv_relu_layer_2', IPReLU()),\n",
        "        ('inv_max_pool_1', nn.ConvTranspose2d(32, 32, 11, 1)),    # 32 x 20 x 20\n",
        "        ('inv_conv_layer_2', nn.ConvTranspose2d(32, 16, 5, 1)),   # 16 x 24 x 24\n",
        "        ('inv_relu_layer_1', IPReLU()),\n",
        "        ('inv_conv_layer_1', nn.ConvTranspose2d(16, 1, 5, 1)),    # 1 x 28 x 28\n",
        "        ('out_layer', nn.Sigmoid())\n",
        "]))\n",
        "\n",
        "model = nn.Sequential(OrderedDict([\n",
        "        ('encoder', encoder),\n",
        "        ('decoder', decoder)\n",
        "]))\n",
        "\n",
        "model = model.to(torch.device('cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB4EmjWpwZes",
        "colab_type": "code",
        "outputId": "28607595-b830-49fd-b12f-c69681de92fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 10\n",
        "\n",
        "# We can use reconstruction loss also. In that case, we will\n",
        "# be maximizing the log likelihood of Normal Distribution.\n",
        "# In this case, I maximize the log likelihood of the bernoulli\n",
        "# distribution by keeping CrossEntropyLoss!\n",
        "def loss_fn(outputs, targets):\n",
        "    return -torch.mean(targets*torch.log(outputs+1e-18) + (1-targets)*torch.log(1-outputs+1e-18))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for i in range(epochs):\n",
        "    for idx in range(x_train.shape[0] // batch_size):\n",
        "        # Get the batch to train\n",
        "        x_batch = x_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "\n",
        "        # Forward pass\n",
        "        recon = model(x_batch)\n",
        "        recon = recon.view(batch_size, 784)\n",
        "        x_batch = x_batch.view(batch_size, 784)\n",
        "        loss = loss_fn(recon, x_batch.long())\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the results\n",
        "        stdout.write(f'\\r epoch : {i}\\t'\n",
        "                     f'step : {min((idx+1)*batch_size, x_train.shape[0])}/{x_train.shape[0]}\\t'\n",
        "                     f'loss : {loss.item():.3f}\\t')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch : 0\tstep : 60000/60000\tloss : 0.276\t\n",
            " epoch : 1\tstep : 60000/60000\tloss : 0.266\t\n",
            " epoch : 2\tstep : 60000/60000\tloss : 0.261\t\n",
            " epoch : 3\tstep : 60000/60000\tloss : 0.239\t\n",
            " epoch : 4\tstep : 60000/60000\tloss : 0.218\t\n",
            " epoch : 5\tstep : 60000/60000\tloss : 0.191\t\n",
            " epoch : 6\tstep : 60000/60000\tloss : 0.166\t\n",
            " epoch : 7\tstep : 60000/60000\tloss : 0.151\t\n",
            " epoch : 8\tstep : 60000/60000\tloss : 0.141\t\n",
            " epoch : 9\tstep : 60000/60000\tloss : 0.125\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNB-bTl3jcj",
        "colab_type": "code",
        "outputId": "63cc8047-e047-42a1-d216-418f0bdaf409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "some = encoder(x_test[:100, ...])\n",
        "decoder(some).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E7SAf5F5B0a",
        "colab_type": "code",
        "outputId": "7dfb8736-738b-4fff-fca0-5bf7b0b60aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "fig, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "ax[0].imshow(x_train[0, 0, ...].cpu())\n",
        "ax[1].imshow(model(x_train[:1, ...])[0, 0, ...].cpu().detach())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WV0vjByCrFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################\n",
        "#   5. Variational Autoencoder   #\n",
        "##################################\n",
        "latent_dims = 20\n",
        "batch_size = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83LyGlHUhy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LocLogvar(nn.Module):\n",
        "    def __init__(self, in_features, latent_dims):\n",
        "        super(LocLogvar, self).__init__()\n",
        "        self.loc = nn.Linear(in_features, latent_dims)\n",
        "        self.logvar = nn.Linear(in_features, latent_dims)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        loc = self.loc(inputs)\n",
        "        logvar = self.logvar(inputs)\n",
        "        return loc, logvar\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X.view(-1, *self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBeHHO7XRNLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in encoder.named_parameters():\n",
        "    if torch.any(torch.isinf(param) | torch.isnan(param)):\n",
        "        print(name + \" contains inf or nan\")\n",
        "for name, param in decoder.named_parameters():\n",
        "    if torch.any(torch.isinf(param) | torch.isnan(param)):\n",
        "        print(name + \" contains inf or nan\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZDpPBm7Lu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(OrderedDict([\n",
        "        ('e_conv_layer_1', nn.Conv2d(1, 16, 5, 1)),                # 16 x 24 x 24\n",
        "        ('e_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_1', nn.BatchNorm2d(16)),\n",
        "        ('e_conv_layer_2', nn.Conv2d(16, 32, 5, 1)),               # 32 x 20 x 20\n",
        "        ('e_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_2', nn.BatchNorm2d(32)),\n",
        "        ('e_conv_layer_3', nn.Conv2d(32, 32, 11, 1)),              # 32 x 10 x 10\n",
        "        ('e_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('e_conv_layer_4', nn.Conv2d(32, 64, 5, 1)),               # 64 x 6 x 6\n",
        "        ('e_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_4', nn.BatchNorm2d(64)),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.75)),\n",
        "        ('e_conv_layer_5', nn.Conv2d(64, 128, 5, 1)),              # 128 x 2 x 2\n",
        "        ('e_relu_layer_5', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_5', nn.BatchNorm2d(128)),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.85)),\n",
        "        ('e_flatten_layer', nn.Flatten()),\n",
        "        ('e_out_layer', LocLogvar(128*2*2, latent_dims))\n",
        "        ]))\n",
        "\n",
        "        self.decoder = nn.Sequential(OrderedDict([\n",
        "        ('inv_linear_layer_1', nn.Linear(latent_dims, 128*2*2)),   # 128 * 2 * 2\n",
        "        ('inv_relu_layer_5', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_flatten_layer', Reshape(128, 2, 2)),                 # 128 x 2 x 2\n",
        "        ('inv_conv_layer_5', nn.ConvTranspose2d(128, 64, 5, 1)),   # 64 x 6 x 6\n",
        "        ('inv_batch_norm_5', nn.BatchNorm2d(64)),\n",
        "        ('inv_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_4', nn.ConvTranspose2d(64, 32, 5, 1)),    # 32 x 10 x 10\n",
        "        ('inv_batch_norm_4', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_3', nn.ConvTranspose2d(32, 32, 11, 1)),   # 32 x 20 x 20\n",
        "        ('inv_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_2', nn.ConvTranspose2d(32, 16, 5, 1)),    # 16 x 24 x 24\n",
        "        ('inv_batch_norm_2', nn.BatchNorm2d(16)),\n",
        "        ('inv_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_1', nn.ConvTranspose2d(16, 1, 5, 1)),     # 1 x 28 x 28\n",
        "        ('inv_batch_norm_1', nn.BatchNorm2d(1)),\n",
        "        ('inv_out_layer', nn.Sigmoid())\n",
        "        ]))\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                         'reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tum6P_gbooRZ",
        "colab_type": "code",
        "outputId": "a4516a3c-3a1b-4056-a031-078dbd3b0b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():\n",
        "        sample = torch.randn(64, latent_dims).to(device)\n",
        "        sample = model.decode(sample).cpu()\n",
        "        save_image(sample.view(64, 1, 28, 28),\n",
        "                    'sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 670.281750\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 495.515719\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 490.594844\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 487.064906\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 482.215844\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 481.045094\n",
            "====> Epoch: 1 Average loss: 493.0808\n",
            "====> Test set loss: 451.4054\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 473.415406\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 472.720031\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 468.290437\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 466.570781\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 460.161625\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 452.271844\n",
            "====> Epoch: 2 Average loss: 464.2420\n",
            "====> Test set loss: 438.1904\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 447.858906\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 442.761656\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 438.802563\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 432.144063\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 427.718469\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 420.924969\n",
            "====> Epoch: 3 Average loss: 433.0071\n",
            "====> Test set loss: 400.3502\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 417.831625\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 412.125563\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 406.925281\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 399.925125\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 394.621812\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 390.543469\n",
            "====> Epoch: 4 Average loss: 400.8322\n",
            "====> Test set loss: 375.5713\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 388.877437\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 379.753781\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 376.297438\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 372.466969\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 369.928406\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 364.283406\n",
            "====> Epoch: 5 Average loss: 373.6413\n",
            "====> Test set loss: 350.2578\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 361.835125\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 359.071969\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 355.398344\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 352.721500\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 349.015594\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 346.695781\n",
            "====> Epoch: 6 Average loss: 352.0378\n",
            "====> Test set loss: 339.3342\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 341.627437\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 338.799906\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 337.726500\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 333.282844\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 331.413250\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 328.779625\n",
            "====> Epoch: 7 Average loss: 334.0098\n",
            "====> Test set loss: 318.2812\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 324.826156\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 324.558625\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 319.597531\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 317.922531\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 314.548563\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 312.795625\n",
            "====> Epoch: 8 Average loss: 318.4819\n",
            "====> Test set loss: 305.0334\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 311.398594\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 309.064062\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 306.919656\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 303.514500\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 301.248562\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 299.085469\n",
            "====> Epoch: 9 Average loss: 304.4925\n",
            "====> Test set loss: 291.0715\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 296.439250\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 294.835219\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 294.409906\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 294.322594\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 288.713625\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 286.543187\n",
            "====> Epoch: 10 Average loss: 292.1033\n",
            "====> Test set loss: 278.3879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLMMZtgtEz4",
        "colab_type": "code",
        "outputId": "c2e2ed98-e051-4859-b9c0-c2f47596f110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    sample = torch.randn(1, latent_dims).to(device)\n",
        "    sample = model.decode(sample).cpu()\n",
        "plt.imshow(sample[0, 0, ...])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzPtSlKcjcgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   5. GAN   #\n",
        "##############\n",
        "latent_dims = 100\n",
        "batch_size = 64\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ7_zQ4G8z1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X.view(-1, *self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWawQr-qp46N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(GAN, self).__init__()\n",
        "\n",
        "        disc = nn.Sequential(OrderedDict([\n",
        "        ('disc_conv_layer_1', nn.Conv2d(1, 16, 5, 1)),                # 16 x 24 x 24\n",
        "        ('disc_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('disc_batch_norm_1', nn.BatchNorm2d(16)),\n",
        "        ('disc_conv_layer_2', nn.Conv2d(16, 32, 5, 1)),               # 32 x 20 x 20\n",
        "        ('disc_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('disc_batch_norm_2', nn.BatchNorm2d(32)),\n",
        "        ('disc_conv_layer_3', nn.Conv2d(32, 32, 11, 1)),              # 32 x 10 x 10\n",
        "        ('disc_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('disc_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('disc_conv_layer_4', nn.Conv2d(32, 64, 5, 1)),               # 64 x 6 x 6\n",
        "        ('disc_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('disc_batch_norm_4', nn.BatchNorm2d(64)),\n",
        "        ('disc_dropout_layer_1', nn.Dropout2d(p=0.75)),\n",
        "        ('disc_flatten_layer', nn.Flatten()),\n",
        "        ('disc_fc_layer_1', nn.Linear(64*6*6, 128)),\n",
        "        ('disc_fc_layer_2', nn.Linear(128, 64)),\n",
        "        ('disc_fc_layer_3', nn.Linear(64, 32)),\n",
        "        ('disc_out_layer', nn.Linear(32, 1))\n",
        "        ]))\n",
        "        self.add_module('disc', disc)\n",
        "\n",
        "        gen = nn.Sequential(OrderedDict([\n",
        "        ('inv_linear_layer_1', nn.Linear(latent_dims, 128*2*2)),   # 128 * 2 * 2\n",
        "        ('inv_relu_layer_5', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_flatten_layer', Reshape(128, 2, 2)),                 # 128 x 2 x 2\n",
        "        ('inv_conv_layer_5', nn.ConvTranspose2d(128, 64, 5, 1)),   # 64 x 6 x 6\n",
        "        ('inv_batch_norm_5', nn.BatchNorm2d(64)),\n",
        "        ('inv_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_4', nn.ConvTranspose2d(64, 32, 5, 1)),    # 32 x 10 x 10\n",
        "        ('inv_batch_norm_4', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_3', nn.ConvTranspose2d(32, 32, 11, 1)),   # 32 x 20 x 20\n",
        "        ('inv_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_2', nn.ConvTranspose2d(32, 16, 5, 1)),    # 16 x 24 x 24\n",
        "        ('inv_batch_norm_2', nn.BatchNorm2d(16)),\n",
        "        ('inv_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_1', nn.ConvTranspose2d(16, 1, 5, 1)),     # 1 x 28 x 28\n",
        "        ('inv_batch_norm_1', nn.BatchNorm2d(1)),\n",
        "        ('inv_out_layer', nn.Sigmoid())\n",
        "        ]))\n",
        "        self.add_module('gen', gen)\n",
        "\n",
        "        self.latent_dims = latent_dims\n",
        "\n",
        "    def forward(self, X):\n",
        "        z = torch.randn(X.shape[0], self.latent_dims, device='cuda')\n",
        "        gen_img = self.gen(z)\n",
        "        gen_labels = self.disc(gen_img)\n",
        "        img_labels = self.disc(X)\n",
        "        return img_labels, gen_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErR56Ec_9Ap9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "model = GAN(latent_dims).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "def loss_function(img_labels, gen_labels, turn='gen'):\n",
        "    if turn == 'gen':\n",
        "        return F.binary_cross_entropy_with_logits(gen_labels, torch.ones_like(gen_labels))\n",
        "    return (F.binary_cross_entropy_with_logits(img_labels, torch.ones_like(img_labels)) +\n",
        "            F.binary_cross_entropy_with_logits(gen_labels, torch.zeros_like(gen_labels)))\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_gen_loss, train_disc_loss = 0, 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        turn = ['gen' if batch_idx&2 == 0 else 'disc']\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        img_labels, gen_labels = model(data)\n",
        "        loss = loss_function(img_labels, gen_labels, turn=turn)\n",
        "        loss.backward()\n",
        "        if turn == 'gen':\n",
        "            train_gen_loss += loss.item()\n",
        "        elif turn == 'disc':\n",
        "            train_disc_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {}\\tStep: [{}/{} ({:.0f}%)]\\tGen Loss: {:.6f}\\tDisc Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                train_gen_loss  / (len(train_loader.dataset) / batch_size + 1),\n",
        "                train_disc_loss / (len(train_loader.dataset) / batch_size + 1)))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    disc_loss, gen_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            img_labels, gen_labels = model(data)\n",
        "            gen_loss += loss_function(img_labels, gen_labels, turn='gen').item()\n",
        "            disc_loss += loss_function(img_labels, gen_labels, turn='disc').item()\n",
        "\n",
        "    gen_loss /= len(test_loader.dataset)\n",
        "    disc_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set gen loss : {:.4f}'.format(gen_loss))\n",
        "    print('====> Test set disc loss: {:.4f}'.format(disc_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33IMDeSOGAiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():\n",
        "        sample = torch.randn(9, latent_dims).to(device)\n",
        "        sample = model.gen(sample).cpu()\n",
        "        save_image(sample.view(9, 1, 28, 28),\n",
        "                    'sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v7ZIAzdKuoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    sample = torch.randn(9, latent_dims).to(device)\n",
        "    sample = model.gen(sample).cpu()\n",
        "plt.imshow(sample[0, 0, ...])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S_rFgUFVbr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}