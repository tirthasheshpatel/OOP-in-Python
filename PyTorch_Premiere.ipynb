{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch > TensorFlow",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirthasheshpatel/OOP-in-Python/blob/master/PyTorch_Premiere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S23tUXpyjRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyUpNZ6yvAZ",
        "colab_type": "code",
        "outputId": "0870ea14-91cb-42d8-d94e-cae8f4452b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# cannot use np.float32 or np.float64 with torch tensors\n",
        "a = torch.arange(0, 50, step=1, dtype=torch.float64).reshape(10,5)\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "print(a.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n",
            "torch.float64\n",
            "torch.Size([10, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlGbwdpy7n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_style_a = a.numpy() # convert to numpy style array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hc2mbte9SBt",
        "colab_type": "code",
        "outputId": "97e90757-d315-4fa9-bdac-d93bfdf2feac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "numpy_style_a"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.,  2.,  3.,  4.],\n",
              "       [ 5.,  6.,  7.,  8.,  9.],\n",
              "       [10., 11., 12., 13., 14.],\n",
              "       [15., 16., 17., 18., 19.],\n",
              "       [20., 21., 22., 23., 24.],\n",
              "       [25., 26., 27., 28., 29.],\n",
              "       [30., 31., 32., 33., 34.],\n",
              "       [35., 36., 37., 38., 39.],\n",
              "       [40., 41., 42., 43., 44.],\n",
              "       [45., 46., 47., 48., 49.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGzeH30I9T0f",
        "colab_type": "code",
        "outputId": "7d63f46a-47cb-4524-d6d7-54011b67f469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# convert numpy to torch style tensor\n",
        "numpy_style_to_torch_style_a = torch.from_numpy(numpy_style_a)\n",
        "print(numpy_style_to_torch_style_a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeyIYvwO91Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.from_numpy(np.random.randn(5, 3)) # Lets generate 2 random tensors\n",
        "b = torch.from_numpy(np.random.randn(3, 5)) # and operate on them"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDh-gTDfvG_V",
        "colab_type": "code",
        "outputId": "6f1662fc-ca49-4339-df7d-db9ff33a2394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(f\"{a}\\n{b}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.5805, -1.0992, -1.1109],\n",
            "        [ 0.1270,  1.0339, -0.7586],\n",
            "        [-0.5404,  0.3662, -1.4402],\n",
            "        [ 1.4080, -0.2514, -0.1445],\n",
            "        [-0.5731,  0.4931,  0.4761]], dtype=torch.float64)\n",
            "tensor([[ 0.5715,  1.7619, -0.0174, -0.5361,  0.1702],\n",
            "        [ 0.4163, -0.6124,  1.6261,  0.0258,  0.3844],\n",
            "        [-1.6465,  0.4759, -2.2006, -0.6972,  1.1951]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5em3PuDJvo0B",
        "colab_type": "code",
        "outputId": "36b5c2a7-a5dd-4380-b560-59f8e3a1b561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# to add,subtract use a+b,a-b\n",
        "# for matrix multiplication\n",
        "c = a @ b # @ -> matrix multiplication\n",
        "print(c)\n",
        "c = torch.mm(a, b) # Equivalent to a@b\n",
        "print(c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1033, -4.4020,  0.7023,  2.1296, -2.1892],\n",
            "        [ 1.7521, -0.7705,  3.3485,  0.4876, -0.4876],\n",
            "        [ 2.2149, -1.8618,  3.7742,  1.3034, -1.6724],\n",
            "        [ 0.9380,  2.5658, -0.1154, -0.6606, -0.0297],\n",
            "        [-0.9062, -1.0852, -0.2359, -0.0120,  0.6611]], dtype=torch.float64)\n",
            "tensor([[-0.1033, -4.4020,  0.7023,  2.1296, -2.1892],\n",
            "        [ 1.7521, -0.7705,  3.3485,  0.4876, -0.4876],\n",
            "        [ 2.2149, -1.8618,  3.7742,  1.3034, -1.6724],\n",
            "        [ 0.9380,  2.5658, -0.1154, -0.6606, -0.0297],\n",
            "        [-0.9062, -1.0852, -0.2359, -0.0120,  0.6611]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYgzjKazwKCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making tensors on GPU :o\n",
        "# See the RAM bar will increase as soon as we create a tensor on GPU\n",
        "a_gpu = torch.arange(0, 50, dtype=torch.float64, device='cuda').reshape(5, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnfNts_LwtHs",
        "colab_type": "code",
        "outputId": "295fc0e7-a252-4e18-fe8a-2fcccdf78c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "a_gpu"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
              "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
              "        [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
              "        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai1YLLfDWevW",
        "colab_type": "code",
        "outputId": "173294fd-6e89-4dd6-e3c1-071f011addde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.is_tensor\n",
        "print(torch.is_tensor([1., 2., 3.]))\n",
        "print(torch.is_tensor(a))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbFnvrpOWwyg",
        "colab_type": "code",
        "outputId": "ee3c9132-0f25-4abd-e8c4-6dd2b2a64d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.set_default_dtype -> set floating point dtype\n",
        "torch.set_default_dtype(torch.float64)\n",
        "a = torch.linspace(0, 10, 100)\n",
        "print(a.dtype)\n",
        "# torch.get_default_dtype\n",
        "print(torch.get_default_dtype())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float64\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawr4hAyXANn",
        "colab_type": "code",
        "outputId": "db707480-fe65-4eb7-9296-b5d7a8eab650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.numel -> same as np.ndarray.size\n",
        "print(torch.numel(a))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42PEyCm-YG-I",
        "colab_type": "code",
        "outputId": "f0389f99-ab77-4298-e0f3-15599990e8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# torch.tensor -> Similar to np.array(data)\n",
        "# ``torch.tensor`` always copies ``data``. To avoid copying\n",
        "# np.ndarray use ``torch.as_tensor`` instead\n",
        "a = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda')\n",
        "print(a)\n",
        "\n",
        "# You can also record gradients on the\n",
        "# operations invloving `a` by setting require_grad=True\n",
        "a = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], device='cuda', requires_grad=True)\n",
        "b = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda', requires_grad=True)\n",
        "# Operate on a and b\n",
        "c = (a @ b).sum()\n",
        "# The graph formed is:\n",
        "# a     b\n",
        "#  \\   /\n",
        "#    c (op: SumBackward)\n",
        "print(c.grad_fn)\n",
        "print(c.backward()) # This just calculates the gradient of c wrt all the nodes in the graph\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n",
            "<SumBackward0 object at 0x7f4937a3e208>\n",
            "None\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n",
            "tensor([[12., 12., 12.],\n",
            "        [15., 15., 15.],\n",
            "        [18., 18., 18.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf5j6K-2Yz1b",
        "colab_type": "code",
        "outputId": "9842fe97-71d3-4cc6-fbb0-e2c739de66e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.sparse_coo_tensor -> create a sparse tensor ==> amazing\n",
        "a = torch.sparse_coo_tensor(torch.empty([1, 0]),\n",
        "                            torch.empty([0, 2]), [1, 2])\n",
        "print(a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(indices=tensor([], size=(1, 0)),\n",
            "       values=tensor([], size=(0, 2)),\n",
            "       size=(1, 2), nnz=0, layout=torch.sparse_coo)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Ril3Lbus7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.as_tensor  -> create a tensor from np.ndarray\n",
        "# torch.as_strided -> np.lib.stride_tricks.as_strided\n",
        "# torch.from_numpy -> as the name suggest\n",
        "# torch.zeros\n",
        "# torch.zeros_like\n",
        "# torch.ones\n",
        "# torch.ones_like\n",
        "# torch.empty\n",
        "# torch.empty_like\n",
        "# torch.full\n",
        "# torch.full_like\n",
        "# torch.arange\n",
        "# torch.linspace\n",
        "# torch.logspace\n",
        "# torch.eye\n",
        "# torch.empty_strided\n",
        "# torch.cat -> np.concatenate\n",
        "# torch.chunk -> Splits a tensor into a specific number of chunks.\n",
        "#                Each chunk is a view of the input tensor\n",
        "# torch.reshape\n",
        "# torch.stack\n",
        "# torch.t -> same as np.ndarray.T ==> Use `torch.tensor.T` instead\n",
        "# torch.transpose\n",
        "# torch.take -> same as np.take\n",
        "# torch.where -> same as np.where"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4mOdnd7nd_",
        "colab_type": "code",
        "outputId": "400acda4-3362-41b9-ba98-866f8de05138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.gather -> Gathers values along an axis specified by `dim` (`axis`)\n",
        "a = torch.arange(10)\n",
        "a_gather = torch.gather(a, dim=0, index=torch.tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7]))\n",
        "print(a_gather)\n",
        "t = torch.tensor([[1,2],[3,4]])\n",
        "print(torch.gather(t, 1, torch.tensor([[0,0],[1,0]])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7])\n",
            "tensor([[1, 1],\n",
            "        [4, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plc3ACy5-7w5",
        "colab_type": "code",
        "outputId": "f06ee5c6-aeb0-4456-bc7c-1da71208144d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.index_seelct -> select the indices along a given `dim` (`axis`)\n",
        "# This operation creates a copy if the `out` argument is not the same shape\n",
        "# as the input tensor.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.index_select(a, 0, torch.tensor([0, 2]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1485,  1.2311, -0.9398,  1.6522],\n",
            "        [ 0.3907,  0.7454,  0.9357, -0.1297],\n",
            "        [ 1.4893, -0.4358,  0.7599, -0.5270]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1485,  1.2311, -0.9398,  1.6522],\n",
              "        [ 1.4893, -0.4358,  0.7599, -0.5270]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv24xIn4-9an",
        "colab_type": "code",
        "outputId": "5aea0cec-d45f-4651-8585-4621c17d976c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.masked_select -> selects the masked entries only.\n",
        "# Always creates a copy.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.masked_select(a, a<=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.4506, -1.6720, -0.1162, -0.2884],\n",
            "        [-1.3088, -0.9825, -1.7120, -1.5537],\n",
            "        [-1.7610, -0.2185, -0.5624,  0.2125]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.4506, -1.6720, -0.1162, -0.2884, -1.3088, -0.9825, -1.7120, -1.5537,\n",
              "        -1.7610, -0.2185, -0.5624])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCg9vWLj_ogQ",
        "colab_type": "code",
        "outputId": "83aaedfd-22d6-4a45-a378-89a4285bfcb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.narrow -> Select the entires from the array\n",
        "# along a particular `dim` starting at `start` and\n",
        "# ending at `end`. Signature: input, dim, start, end.\n",
        "# Its a view, not a copy\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.narrow(a, 0, 1, 2) # 2 inclusive"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9397, -1.7107,  0.5253, -2.0273],\n",
            "        [-0.9441, -1.7766, -0.7201, -0.4047],\n",
            "        [-0.7126, -2.2422, -0.6421,  0.6445]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9441, -1.7766, -0.7201, -0.4047],\n",
              "        [-0.7126, -2.2422, -0.6421,  0.6445]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMwjAh7NAwWc",
        "colab_type": "code",
        "outputId": "ff033854-cd2e-4268-8335-7ab87e0651c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.reshape -> Creates a view whenever possible\n",
        "# use torch.as_strided for garunteed view.\n",
        "a = torch.randn(1, 2, 3, 4, 5)\n",
        "print(a.shape)\n",
        "torch.reshape(a, [5, 4, 3, 2, 1]).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3, 4, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsLVv5uEB6Kp",
        "colab_type": "code",
        "outputId": "df427a69-a427-48d8-ca2d-78492851f6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# torch.split -> Splits the tensor into chunks.\n",
        "# Each chunk is a view of the original tensor.\n",
        "a = torch.randn(3, 5)\n",
        "print(a)\n",
        "print(torch.split(a, [1, 4], dim=1)[0])\n",
        "print(torch.split(a, [1, 4], dim=1)[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.0958,  1.4055,  0.1653,  1.2995, -0.3636],\n",
            "        [ 0.8857,  0.8923, -0.0155,  0.1630, -1.8609],\n",
            "        [ 0.0103,  0.3413, -0.3054,  0.3792, -0.0331]])\n",
            "tensor([[2.0958],\n",
            "        [0.8857],\n",
            "        [0.0103]])\n",
            "tensor([[ 1.4055,  0.1653,  1.2995, -0.3636],\n",
            "        [ 0.8923, -0.0155,  0.1630, -1.8609],\n",
            "        [ 0.3413, -0.3054,  0.3792, -0.0331]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueS1jnC-DTio",
        "colab_type": "code",
        "outputId": "109b7026-2576-4272-cc85-b676a951ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# torch.squeeze -> same as np.squeeze\n",
        "a = torch.randn(5, 1, 1, 4, 1, 1, 3, 1, 1, 2)\n",
        "print(a.shape)\n",
        "b = torch.squeeze(a)\n",
        "print(b.shape)\n",
        "# torch.unsqueeze -> wow!\n",
        "torch.unsqueeze(b, -1).shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 1, 4, 1, 1, 3, 1, 1, 2])\n",
            "torch.Size([5, 4, 3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bd_jd2BEldK",
        "colab_type": "code",
        "outputId": "6e406b23-9f6d-42ad-c772-f5eca02f3f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.where -> if `condition`, `x`, else `y`\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.where(a>2, a, 1-a)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, -1],\n",
              "        [ 3,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63mbiDnHRzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                       Random Sampling in Torch!!\n",
        "# torch.seed\n",
        "# torch.set_rng_state\n",
        "# torch.get_rng_state\n",
        "# torch.rand\n",
        "# torch.rand_like\n",
        "# torch.randint\n",
        "# torch.randint_like\n",
        "# torch.randn\n",
        "# torch.randn_like\n",
        "# torch.randperm -> Returns a random permutation of integers from `0` to `n-1`.\n",
        "# torch.bernoulli\n",
        "# torch.multinomial\n",
        "# torch.poisson\n",
        "# torch.normal\n",
        "\n",
        "#                       Inplace Random Sampling\n",
        "# =========================     =========================================================\n",
        "#         CODE                                         DOCUMENTATION\n",
        "# =========================     =========================================================\n",
        "# torch.Tensor.bernoulli_()   - in-place version of torch.bernoulli()\n",
        "# torch.Tensor.cauchy_()      - numbers drawn from the Cauchy distribution\n",
        "# torch.Tensor.exponential_() - numbers drawn from the exponential distribution\n",
        "# torch.Tensor.geometric_()   - elements drawn from the geometric distribution\n",
        "# torch.Tensor.log_normal_()  - samples from the log-normal distribution\n",
        "# torch.Tensor.normal_()      - in-place version of torch.normal()\n",
        "# torch.Tensor.random_()      - numbers sampled from the discrete uniform distribution\n",
        "# torch.Tensor.uniform_()     - numbers sampled from the continuous uniform distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikteJICdIOAq",
        "colab_type": "code",
        "outputId": "16aa8068-e278-4a0a-f93b-23e38f08502f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Serialization\n",
        "# torch.save -> Saves tensor objects and model in pickle file\n",
        "# torch.load -> Loads tensor objects and model from a pickle file\n",
        "a = torch.arange(10)\n",
        "torch.save(a, 'torch_tensor_a.pkl')\n",
        "a = torch.load('torch_tensor_a.pkl')\n",
        "a"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcyTevew_7y2",
        "colab_type": "code",
        "outputId": "fadd013f-4d9b-4fb8-d21f-a13fef1f1351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Parallelism\n",
        "# torch.get_num_threads()\n",
        "# torch.set_num_threads()\n",
        "# torch.get_num_inteop_threads()\n",
        "# torch.set_num_interop_threads()\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(4)\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(1)\n",
        "print(torch.get_num_threads())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "4\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfy6fkaAAiF",
        "colab_type": "code",
        "outputId": "e093b3ad-acdd-4384-cc07-7dc2a9aa087a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.no_grad() -> Context manager to disable backprop for\n",
        "#                    some particular operation. This means that\n",
        "#                    the operation will not be recorded on graph.\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    c = a * b\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEbwIIhBiHz",
        "colab_type": "code",
        "outputId": "48dc8891-e2b0-4970-ad7a-b42f6364e919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# torch.enable_grad() -> Enablewe grad for operations where grad computation\n",
        "#                        has been altered using torch.no_grad or torch.set_grad_enabled\n",
        "# Method 1\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    with torch.enable_grad():\n",
        "        c = a * b\n",
        "print(c.requires_grad)\n",
        "\n",
        "# Method 2\n",
        "@torch.enable_grad()\n",
        "def mul_op(x, y):\n",
        "    return x * y\n",
        "\n",
        "with torch.no_grad():\n",
        "    c = mul_op(a, b)\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slupOmQCbj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Math operations\n",
        "# torch.abs\n",
        "# torch.acos\n",
        "# torch.asin\n",
        "# torch.atan\n",
        "# torch.atan2\n",
        "# torch.sin\n",
        "# torch.cos\n",
        "# torch.cosh\n",
        "# torch.tanh\n",
        "# torch.sinh\n",
        "# torch.tan\n",
        "# torch.exp\n",
        "# torch.log\n",
        "# torch.log10\n",
        "# torch.log2\n",
        "# torch.pow\n",
        "# torch.div\n",
        "# torch.add\n",
        "# torch.mul\n",
        "# torch.reciprocal\n",
        "# torch.remainder\n",
        "# torch.round\n",
        "# torch.rsqrt\n",
        "# torch.sqrt\n",
        "# torch.sigmoid\n",
        "# torch.sign\n",
        "# torch.square\n",
        "# torch.true_devide\n",
        "# torch.trunc -> truncate a floting point into integer\n",
        "# torch.argmax\n",
        "# torch.argmin\n",
        "# torch.max\n",
        "# torch.min\n",
        "# torch.dist -> Computes the p-norm of a tensor (default p=2)\n",
        "# torch.logsumexp\n",
        "# torch.mean\n",
        "# torch.median\n",
        "# torch.mode\n",
        "# torch.std\n",
        "# torch.std_mean\n",
        "# torch.var\n",
        "# torch.var_mean\n",
        "# torch.sum\n",
        "# torch.prod\n",
        "# torch.cumsum\n",
        "# torch.cumprod\n",
        "# torch.unique\n",
        "# torch.diag -> same as np.diag\n",
        "# torch.cholesky\n",
        "# torch.cholesky_solve\n",
        "# torch.solve\n",
        "# torch.triangular_solve\n",
        "# torch.lu\n",
        "# torch.lu_solve\n",
        "# torch.qr\n",
        "# torch.svd\n",
        "# torch.scd_lowrank\n",
        "# torch.pca_lowrank\n",
        "# torch.symeig -> Eigenvalues and vectors for symetric matrices\n",
        "# torch.matrix_power\n",
        "# torch.matrix_rank\n",
        "# torch.eig\n",
        "# torch.det\n",
        "# torch.logdet\n",
        "# torch.slogdet\n",
        "# torch.trace\n",
        "# torch.tril -> Returns the lower triangular part of input\n",
        "# torch.triu\n",
        "# torch.lstsq\n",
        "# torch.inverse  -> same as np.inv\n",
        "# torch.pinverse -> same as np.pinv\n",
        "# torch.flatten\n",
        "# torch.norm -> Computes the norm of a matrix or vector\n",
        "# torch.add -> Can be used as axpy but for tensors\n",
        "# torch.addcdiv -> Performs the element-wise division of `tensor1` by `tensor2`,\n",
        "#                  multiply the result by the scalar `value` and add it to `input`\n",
        "#                  result = input + value * (tensor1 / tensor2)\n",
        "# torch.addcmul -> Same as addcdiv but for multiplecation\n",
        "# torch.bitwise_not -> oeprator |\n",
        "# torch.bitwise_and -> operator &\n",
        "# torch.bitwise_not\n",
        "# torch.bitwise_xor\n",
        "# torch.ceil\n",
        "# torch.floor\n",
        "# torch.angle -> Commutes the angle of each vector (complex number function)\n",
        "# torch.conj -> Computes the conjugate of each vector (complex number function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tADWFzJiF4LZ",
        "colab_type": "code",
        "outputId": "a4da3355-5659-4ee4-9478-a26418a138c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# torch.clamp -> works like `np.clip`. Clips a tensor in [min, max] range\n",
        "a = torch.arange(0, 20)\n",
        "print(a)\n",
        "a = torch.clamp(a, min=5, max=15)\n",
        "print(a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "tensor([ 5,  5,  5,  5,  5,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
            "        15, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CQEJfsoIRM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Advanced Mathematical Operations\n",
        "# torch.digamma -> Derivative of log of gamma function => d/dx ( ln(gamma(input)) )\n",
        "# torch.erf -> Error function\n",
        "# torch.erfc -> Complement of the error function\n",
        "# torch.erfinv -> Inverse of the error function\n",
        "# torch.exp\n",
        "# torch.expm1\n",
        "# torch.log1p -> inverse of torch.expm1\n",
        "# torch.floor_devide\n",
        "# torch.fmod -> Float %\n",
        "# torch.frac -> Computes the fractional portion of each element in `input`\n",
        "# torch.lerp -> out = start + weight * (end - start)\n",
        "# torch.lgamma -> Logirithm of the gamma function\n",
        "# torch.mvlgamma -> Compute the multivariate log gamma function\n",
        "# torch.polygamma -> Compute the n'th derivative of `torch.digamma` function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAti9avJivi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparison Ops\n",
        "# torch.equal\n",
        "# torch.eq\n",
        "# torch.ne\n",
        "# torch.ge\n",
        "# torch.le\n",
        "# torch.gt\n",
        "# torch.lt\n",
        "# torch.allclose\n",
        "# torch.isfinite\n",
        "# torch.isinf\n",
        "# torch.isnan\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgrPg-5S7rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.sort\n",
        "# torch.argsort\n",
        "# torch.topk\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEISpvkXfnrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: BLAS and LAPACK functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XURzQke-fr0-",
        "colab_type": "code",
        "outputId": "ab07c128-aff8-4123-b3a7-a1a3608b1f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "#                           NEURAL NETWORKS IN PYTORCH                          #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "torch.set_default_dtype(torch.float32)\n",
        "torch.manual_seed(420)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f48ee80f170>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDg8dEpiG7t",
        "colab_type": "code",
        "outputId": "cc883127-6a3c-47f1-ee37-25a2a8d6be0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# torch.nn.Parameter -> Registers a parameter in the scope of the module.\n",
        "#                       Doesn't backpropogate if used in or from other module,\n",
        "#                       unless registered.\n",
        "a = torch.randn(4, 5)\n",
        "print(a)\n",
        "nn.Parameter(a)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0070,  0.5044,  0.6704, -0.3829,  0.0938],\n",
            "        [-2.0492,  1.0550, -0.6222,  0.5020,  0.7538],\n",
            "        [ 0.6128, -0.9300,  1.3646, -0.7372, -0.7084],\n",
            "        [-0.2842, -1.4816,  0.3298,  0.4856,  0.4131]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0070,  0.5044,  0.6704, -0.3829,  0.0938],\n",
              "        [-2.0492,  1.0550, -0.6222,  0.5020,  0.7538],\n",
              "        [ 0.6128, -0.9300,  1.3646, -0.7372, -0.7084],\n",
              "        [-0.2842, -1.4816,  0.3298,  0.4856,  0.4131]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXW5LTQfiW-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.Module -> A class to create your NN. Define `__init__` to\n",
        "#                    initialize model parameters and `forward` method\n",
        "#                    to define operations on the parameters and input.\n",
        "#                    Registered parameters will be backpropogated while\n",
        "#                    training.\n",
        "class LinearRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LinearRegressor, self).__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_features, 1))\n",
        "        self.b = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.w + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9XskQqioFbA",
        "colab_type": "code",
        "outputId": "5ee67630-1264-42f3-c06d-c7dcd5e3b9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Preparing Data\n",
        "import matplotlib.pyplot as plt\n",
        "n_examples = 10\n",
        "n_features = 1\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "y_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "plt.scatter(X, y_true)\n",
        "plt.title('Generated Data')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7y2XJ7BlOjG",
        "colab_type": "code",
        "outputId": "f19dc6e3-7c74-4def-9e50-72bbbba47efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Initialize the LinearRegressor model.\n",
        "model = LinearRegressor(n_features)\n",
        "print(model(X))\n",
        "# .parameters() `yields` the parameters.\n",
        "# Not a list of parameters.\n",
        "print([i for i in model.parameters()])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9310],\n",
            "        [ 0.0286],\n",
            "        [ 1.1748],\n",
            "        [ 0.5521],\n",
            "        [ 0.4158],\n",
            "        [-2.0681],\n",
            "        [ 0.3057],\n",
            "        [-0.5863],\n",
            "        [-0.1718],\n",
            "        [-1.4015]], grad_fn=<AddBackward0>)\n",
            "[Parameter containing:\n",
            "tensor([[-0.8565]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0513], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr4CTh9SnKLM",
        "colab_type": "code",
        "outputId": "b6c84af3-a870-4f6b-a944-ee317edd8ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training a torch.nn.Module() model\n",
        "from time import sleep\n",
        "from sys import stdout\n",
        "epochs = 100\n",
        "# torch.nn contains many loss functions. We use\n",
        "# mse loss with mean over all the examples.\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "# torch.optim contains many optimizers like Adam, Momentum\n",
        "# SGD, Adagrad, Adadelta, RMSProp, Nesterov Momentum, etc\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_pred = model(X) # Compute the prediction by forward propogating\n",
        "\n",
        "    loss = loss_fn(y_pred, y_true) # Evaluate the loss function\n",
        "    # Print the loss\n",
        "    stdout.write(f'\\repoch: {i} \\t {20*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f}')\n",
        "    optimizer.zero_grad() # Initialize the optimizer\n",
        "    # Backpropogate through the graph. This will compute the\n",
        "    # gradients of all the parameters in-place and store them\n",
        "    # in .grad() method of the parameters.\n",
        "    loss.backward()\n",
        "    optimizer.step() # Take one step of optimizer. This will update our parameters.\n",
        "    sleep(0.2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.017"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06D8Kj1Qp2uY",
        "colab_type": "code",
        "outputId": "b0cf1c00-fb76-49ce-fd74-067eba51836f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Let's see how good did we perform\n",
        "print(w_true)\n",
        "print(b_true)\n",
        "params = [i for i in model.parameters()]\n",
        "print(params[0])\n",
        "print(params[1])\n",
        "print(y_true)\n",
        "print(model(X))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5441]])\n",
            "tensor([0.5470])\n",
            "Parameter containing:\n",
            "tensor([[0.4573]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.5397], requires_grad=True)\n",
            "tensor([[ 1.1738],\n",
            "        [ 0.6697],\n",
            "        [-0.1860],\n",
            "        [ 0.2040],\n",
            "        [ 0.2006],\n",
            "        [ 1.8688],\n",
            "        [ 0.2579],\n",
            "        [ 0.8006],\n",
            "        [ 0.5921],\n",
            "        [ 1.4782]])\n",
            "tensor([[ 1.0641],\n",
            "        [ 0.5518],\n",
            "        [-0.0602],\n",
            "        [ 0.2723],\n",
            "        [ 0.3451],\n",
            "        [ 1.6712],\n",
            "        [ 0.4039],\n",
            "        [ 0.8801],\n",
            "        [ 0.6588],\n",
            "        [ 1.3153]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f9VmRAQq3O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Somethings to remember about torch.nn.Module()\n",
        "# ============================================================================================= #\n",
        "#                                      Some Methods to remember                                 #\n",
        "# ============================================================================================= #\n",
        "# add_module(name, module) -> Add a sub module that will be registered\n",
        "#                             and affected by changes to the main module\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# apply(fn) -> Apply a function to all the submodules and the main module\n",
        "#              The function `fn` takes a module `m` as an argument\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# children() -> Generator of the children of the model (generates only the module)\n",
        "# named_children() -> Generator of the children of the model (generates the module and its name)\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# modules() -> Generates the modules in the scope of the main module\n",
        "# named_modules() -> Generates name along wwith module\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# parameters() -> Generator of the parameters in the main and sub modules\n",
        "# named_parameters() -> Generates name along with their object\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# cpu()   -> Move all parameters and buffers to cpu\n",
        "# cuda()  -> Move all parameters and buffers to gpu\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# double() -> Casts all the parameters/buffers to double (float64) datatype\n",
        "# float()  -> Casts all the parameters/buffers to float (float32) datatype\n",
        "# half()   -> Casts all the parameters/buffers to half datatype\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# extra_repr() -> Sets the extra representation of the module to print custom info\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# register_forward_hook(hook) -> Registers a forward hook on the module.\n",
        "#                                The hook will be called every time after forward()\n",
        "#                                has computed an output.\n",
        "#                                It should have the signature hook(module, input, output)\n",
        "# register_forward_pre_hood(hook) -> Called before the call to forward(). Must have signature\n",
        "#                                    hook(module, input) -> None or modified input.\n",
        "# register_parameter(name, tensor) -> Register a parameter in a module so the gradients will be\n",
        "#                                     propogated when backward is called.\n",
        "# requires_grad_() -> Used to finetune models. Setting it false disables the backprob state of\n",
        "#                     parameters with which it is called. You can finetune models be disabling\n",
        "#                     some gradients.\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# to() -> See the docs to understand it properly.\n",
        "# ============================================================================================= #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvIIXgWQNvRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An example of `add_module`\n",
        "class LogisticRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticRegressor, self).__init__()\n",
        "        self.add_module('lm', LinearRegressor(n_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.lm(X)\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57PH7CIOwsp",
        "colab_type": "code",
        "outputId": "8abf90d1-5a72-4725-c642-b77f652f5738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Let's see how `add_module` works\n",
        "model = LogisticRegressor(n_features)\n",
        "model(X)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3267],\n",
              "        [0.3550],\n",
              "        [0.3900],\n",
              "        [0.3708],\n",
              "        [0.3666],\n",
              "        [0.2949],\n",
              "        [0.3633],\n",
              "        [0.3367],\n",
              "        [0.3490],\n",
              "        [0.3133]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONgsz7Y1O00j",
        "colab_type": "code",
        "outputId": "61c26072-6527-439c-cde2-67cfc24047bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Example of `children` method\n",
        "list(model.children())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LinearRegressor()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXk55XmO3Pv",
        "colab_type": "code",
        "outputId": "318563db-98a0-44b3-8137-b09ad1ee977c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Example of torch.apply\n",
        "@torch.no_grad()\n",
        "def apply_func(m):\n",
        "    # m is a module so we can preprocess\n",
        "    # parameters if we want to.\n",
        "    m.w = nn.Parameter(torch.tensor([[1.], [2.], [3.], [4.]]))\n",
        "    m.b = nn.Parameter(torch.tensor([1.]))\n",
        "\n",
        "model.apply(apply_func)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressor(\n",
              "  (lm): LinearRegressor()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnenQlDMQi_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some special modules\n",
        "# 1. torch.nn.Sequential -> A sequential model\n",
        "# 2. torch.nn.ModuleList -> Module with multiple sub-modules passed as a list\n",
        "# 3. torch.nn.ModuleDict -> Module with multiple sub-modules passed as a ordered dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxwGZqcDb-hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================================= #\n",
        "#                                       Models! Models! Models!                                 #\n",
        "# ============================================================================================= #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AEA7bIJcz36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################\n",
        "#   1. Linear Regression   #\n",
        "############################\n",
        "n_examples = 10\n",
        "n_features = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGFG_F-chH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Define Model\n",
        "class LinearRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LinearRegressor, self).__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_features, 1))\n",
        "        self.b = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.w + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqRH1Psvc_PX",
        "colab_type": "code",
        "outputId": "d96e4ddd-25bf-44d4-a80b-fa8f8ef017c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Step 2: Prepare Data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "\n",
        "y_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "\n",
        "if n_features == 1:\n",
        "    plt.scatter(X, y_true)\n",
        "    plt.title('Generated Data')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVQW284YdVhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Initialize the LinearRegressor model.\n",
        "model = LinearRegressor(n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woR3BGyldfHr",
        "colab_type": "code",
        "outputId": "99e2a5a5-76b9-4aec-bb7d-63ca74c848e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {20*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.024"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxMGs0Bvd-jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "#   1. Logistic Regression   #\n",
        "##############################\n",
        "n_examples = 10\n",
        "n_features = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHl1NA7zd0cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Define Model\n",
        "class LogisticRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticRegressor, self).__init__()\n",
        "        self.add_module('lm', LinearRegressor(n_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.lm(X)\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jspJmUyeJPv",
        "colab_type": "code",
        "outputId": "4aa0f0f8-87f3-4116-b13f-8024977f8aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Step 2: Prepare Data\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "\n",
        "f_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "y_true = 1.*(torch.sigmoid(f_true) >= 0.5)\n",
        "\n",
        "if n_features == 1:\n",
        "    plt.scatter(X, y_true)\n",
        "    plt.title('Generated Data')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5JEk6Cyec72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Initialize the LogisticRegressor model.\n",
        "model = LogisticRegressor(n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "derj8X0Dey1V",
        "colab_type": "code",
        "outputId": "713c7490-840f-48d6-b825-a59b85ec969b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 100\n",
        "\n",
        "loss_fn   = nn.BCELoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_proba = model(X)\n",
        "    y_pred  = 1.*(y_proba >= 0.5)\n",
        "    loss = loss_fn(y_proba, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {30*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f} \\t'\n",
        "                 f' acc: {torch.sum(y_pred == y_true) / float(n_examples):.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 99 \t loss: 0.576 \t acc: 0.600"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsQNWYmugWo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   1. ANN   #\n",
        "##############\n",
        "n_examples = 100\n",
        "n_features = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BHXYVSciSJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We complete steps 1 and 3 in one step by using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPA99jdCjJcG",
        "colab_type": "code",
        "outputId": "9f3f27dd-6eff-4ae4-e2a1-3c9bf4278e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's peek into the model and see its parameters.\n",
        "dict(model.named_parameters()).keys()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['0.weight', '0.bias', '2.weight', '2.bias', '4.weight', '4.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVm3NrEqjLIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Prepare data\n",
        "X = torch.randn(n_examples, n_features)\n",
        "f_true = (torch.logsumexp(X, dim=1, keepdim=True) +\n",
        "          0.01*torch.randn(n_examples, 1))\n",
        "f_true = torch.sigmoid(f_true-f_true.mean())\n",
        "y_true = 1.*(f_true >= 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7PJ-Hrek7xt",
        "colab_type": "code",
        "outputId": "cee9e540-dc66-4ce1-e3e9-4c29f023c14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 4: Train!\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    f_pred = model(X)\n",
        "    y_pred  = 1.*(torch.sigmoid(f_pred) >= 0.5)\n",
        "    loss = loss_fn(f_pred, y_true)\n",
        "    stdout.write(f'\\repoch: {i} \\t {30*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f} \\t'\n",
        "                 f' acc: {torch.sum(y_pred == y_true) / float(n_examples):.3f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sleep(0.2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 19 \t loss: 0.051 \t acc: 0.990"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP6_YGSvk81h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   1. CNN   #\n",
        "##############\n",
        "torch.set_default_dtype(torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ0UPmam4nEA",
        "colab_type": "code",
        "outputId": "f82eb93a-02fd-459f-bd24-a59c6b0e79c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train / 255.).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_test = (x_test / 255.).reshape(-1, 1, 28, 28).astype('float32')\n",
        "y_train, y_test = ((y_train).astype('float32'),\n",
        "                   (y_test).astype('float32'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCgazCqb4vMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = (torch.as_tensor(x_train, device='cuda'),\n",
        "                                    torch.as_tensor(x_test, device='cuda'),\n",
        "                                    torch.as_tensor(y_train, device='cuda'),\n",
        "                                    torch.as_tensor(y_test, device='cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE8A--vk5UNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "model = nn.Sequential(OrderedDict(\n",
        "    [('conv_layer_1'   , nn.Conv2d(1, 16, 3, 1)),    # 16 x 26 x 26\n",
        "     ('relu_1'         , nn.ReLU()),\n",
        "     ('conv_layer_2'   , nn.Conv2d(16, 32, 3, 1)),   # 32 x 24 x 24\n",
        "     ('relu_2'         , nn.ReLU()),\n",
        "     ('maxpool_layer_1', nn.MaxPool2d(2, stride=2)), # 32 x 12 x 12\n",
        "     ('conv_layer_3'   , nn.Conv2d(32, 64, 3, 1)),   # 64 x 10 x 10\n",
        "     ('relu_3'         , nn.ReLU()),                 #     |\n",
        "     ('flatten_layer'  , nn.Flatten()),              #     |\n",
        "     ('linear_layer_1' , nn.Linear(64*10*10, 64)),   # <----\n",
        "     ('relu_4'         , nn.ReLU()),\n",
        "     ('linear_layer_2' , nn.Linear(64, 32)),\n",
        "     ('relu_5'         , nn.ReLU()),\n",
        "     ('out_layer'      , nn.Linear(32, 10))]\n",
        "))\n",
        "model = model.to(torch.device('cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzQAEu0t7DUI",
        "colab_type": "code",
        "outputId": "c2e1f4bd-63a3-4fca-ea44-ecefa7c14785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 10\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "    for idx in range(x_train.shape[0] // batch_size):\n",
        "        # Get the batch to train\n",
        "        x_batch = x_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "        y_batch = y_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "\n",
        "        # Forward pass\n",
        "        f_pred = model(x_batch)\n",
        "        y_pred = nn.functional.softmax(f_pred, dim=1)\n",
        "        loss = loss_fn(f_pred, y_batch.long())\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the results\n",
        "        stdout.write(f'\\r epoch : {i}\\t'\n",
        "                     f'step : {min((idx+1)*batch_size, x_train.shape[0])}/{x_train.shape[0]}\\t'\n",
        "                     f'loss : {loss.item():.3f}\\t'\n",
        "                     f'accuracy : {torch.sum(1.*(y_pred.argmax(axis=1) == y_batch)) / y_batch.shape[0]:.3f}')\n",
        "    print()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch : 0\tstep : 60000/60000\tloss : 0.275\taccuracy : 0.929\n",
            " epoch : 1\tstep : 60000/60000\tloss : 0.160\taccuracy : 0.960\n",
            " epoch : 2\tstep : 60000/60000\tloss : 0.110\taccuracy : 0.976\n",
            " epoch : 3\tstep : 60000/60000\tloss : 0.082\taccuracy : 0.985\n",
            " epoch : 4\tstep : 60000/60000\tloss : 0.069\taccuracy : 0.989\n",
            " epoch : 5\tstep : 60000/60000\tloss : 0.059\taccuracy : 0.991\n",
            " epoch : 6\tstep : 60000/60000\tloss : 0.053\taccuracy : 0.990\n",
            " epoch : 7\tstep : 60000/60000\tloss : 0.047\taccuracy : 0.991\n",
            " epoch : 8\tstep : 60000/60000\tloss : 0.045\taccuracy : 0.992\n",
            " epoch : 9\tstep : 60000/60000\tloss : 0.040\taccuracy : 0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDd-qXCo7xV8",
        "colab_type": "code",
        "outputId": "a3459b5d-ccbb-42dd-b813-817d9c19a034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_probs_test = model(x_test)\n",
        "y_preds_test = y_probs_test.argmax(axis=1)\n",
        "print(f\"Test set accuracy : {torch.sum(1.*(y_preds_test == y_test)) / y_test.shape[0]}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy : 0.9872999787330627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0IxZFl5r0vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "#   4. Autoencoder   #\n",
        "######################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLgzycPIuDgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Prepare data\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = (1.*((x_train / 255.)>=0.5)).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_test = (1.*((x_test / 255.)>=0.5)).reshape(-1, 1, 28, 28).astype('float32')\n",
        "x_train, x_test = (torch.as_tensor(x_train, device='cuda'),\n",
        "                   torch.as_tensor(x_test, device='cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtZfMzcGuhjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 and 3\n",
        "from functools import partial\n",
        "#  IPReLU => inplace relu\n",
        "IPReLU = partial(nn.ReLU, True)\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, X, *args, **kwargs):\n",
        "        return X.view(-1, *self.shape)\n",
        "\n",
        "encoder = nn.Sequential(OrderedDict([\n",
        "        ('e_conv_layer_1', nn.Conv2d(1, 16, 5, 1)),               # 16 x 24 x 24\n",
        "        ('e_relu_layer_1', IPReLU()),\n",
        "        ('e_conv_layer_2', nn.Conv2d(16, 32, 5, 1)),              # 32 x 20 x 20\n",
        "        ('e_relu_layer_2', IPReLU()),\n",
        "        ('e_max_pool_layer_1', nn.MaxPool2d(2, 2)),               # 32 x 10 x 10\n",
        "        ('e_conv_layer_3', nn.Conv2d(32, 64, 5, 1)),              # 64 x 6 x 6\n",
        "        ('e_relu_layer_3', IPReLU()),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.75)),\n",
        "        ('e_conv_layer_4', nn.Conv2d(64, 128, 5, 1)),             # 128 x 2 x 2\n",
        "        ('e_relu_layer_4', IPReLU()),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.85)),\n",
        "        ('e_flatten_layer', nn.Flatten()),\n",
        "        ('e_linear_layer_1', nn.Linear(128*2*2, 64))              # 64 ==> Bottleneck\n",
        "]))\n",
        "\n",
        "decoder = nn.Sequential(OrderedDict([\n",
        "        ('inv_linear_layer_1', nn.Linear(64, 128*2*2)),           # 128 * 2 * 2\n",
        "        ('inv_relu_layer_4', IPReLU()),\n",
        "        ('inv_flatten_layer', Reshape(128, 2, 2)),                # 128 x 2 x 2\n",
        "        ('inv_conv_layer_4', nn.ConvTranspose2d(128, 64, 5, 1)),  # 64 x 6 x 6\n",
        "        ('inv_relu_layer_3', IPReLU()),\n",
        "        ('inv_conv_layer_3', nn.ConvTranspose2d(64, 32, 5, 1)),   # 32 x 10 x 10\n",
        "        ('inv_relu_layer_2', IPReLU()),\n",
        "        ('inv_max_pool_1', nn.ConvTranspose2d(32, 32, 11, 1)),    # 32 x 20 x 20\n",
        "        ('inv_conv_layer_2', nn.ConvTranspose2d(32, 16, 5, 1)),   # 16 x 24 x 24\n",
        "        ('inv_relu_layer_1', IPReLU()),\n",
        "        ('inv_conv_layer_1', nn.ConvTranspose2d(16, 1, 5, 1)),    # 1 x 28 x 28\n",
        "        ('out_layer', nn.Sigmoid())\n",
        "]))\n",
        "\n",
        "model = nn.Sequential(OrderedDict([\n",
        "        ('encoder', encoder),\n",
        "        ('decoder', decoder)\n",
        "]))\n",
        "\n",
        "model = model.to(torch.device('cuda'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB4EmjWpwZes",
        "colab_type": "code",
        "outputId": "fe251b79-02cb-47a6-c9a9-b638be794944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 10\n",
        "\n",
        "# We can use reconstruction loss also. In that case, we will\n",
        "# be maximizing the log likelihood of Normal Distribution.\n",
        "# In this case, I maximize the log likelihood of the bernoulli\n",
        "# distribution by keeping CrossEntropyLoss!\n",
        "def loss_fn(outputs, targets):\n",
        "    return -torch.mean(targets*torch.log(outputs+1e-18) + (1-targets)*torch.log(1-outputs+1e-18))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for i in range(epochs):\n",
        "    for idx in range(x_train.shape[0] // batch_size):\n",
        "        # Get the batch to train\n",
        "        x_batch = x_train[idx*batch_size:(idx+1)*batch_size, ...]\n",
        "\n",
        "        # Forward pass\n",
        "        recon = model(x_batch)\n",
        "        recon = recon.view(batch_size, 784)\n",
        "        x_batch = x_batch.view(batch_size, 784)\n",
        "        loss = loss_fn(recon, x_batch.long())\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the results\n",
        "        stdout.write(f'\\r epoch : {i}\\t'\n",
        "                     f'step : {min((idx+1)*batch_size, x_train.shape[0])}/{x_train.shape[0]}\\t'\n",
        "                     f'loss : {loss.item():.3f}\\t')\n",
        "    print()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch : 0\tstep : 60000/60000\tloss : 0.276\t\n",
            " epoch : 1\tstep : 60000/60000\tloss : 0.266\t\n",
            " epoch : 2\tstep : 60000/60000\tloss : 0.261\t\n",
            " epoch : 3\tstep : 60000/60000\tloss : 0.238\t\n",
            " epoch : 4\tstep : 60000/60000\tloss : 0.212\t\n",
            " epoch : 5\tstep : 60000/60000\tloss : 0.188\t\n",
            " epoch : 6\tstep : 60000/60000\tloss : 0.166\t\n",
            " epoch : 7\tstep : 60000/60000\tloss : 0.148\t\n",
            " epoch : 8\tstep : 60000/60000\tloss : 0.136\t\n",
            " epoch : 9\tstep : 60000/60000\tloss : 0.126\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNB-bTl3jcj",
        "colab_type": "code",
        "outputId": "060b678a-c68f-4f65-d8f0-0d083376ce1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "some = encoder(x_test[:100, ...])\n",
        "decoder(some).shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E7SAf5F5B0a",
        "colab_type": "code",
        "outputId": "19012fa9-b5d5-4838-cbe1-5402f37352ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "fig, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "ax[0].imshow(x_train[0, 0, ...].cpu())\n",
        "ax[1].imshow(model(x_train[:1, ...])[0, 0, ...].cpu().detach())\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WV0vjByCrFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################\n",
        "#   5. Variational Autoencoder   #\n",
        "##################################\n",
        "latent_dims = 20\n",
        "batch_size = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83LyGlHUhy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LocLogvar(nn.Module):\n",
        "    def __init__(self, in_features, latent_dims):\n",
        "        super(LocLogvar, self).__init__()\n",
        "        self.loc = nn.Linear(in_features, latent_dims)\n",
        "        self.logvar = nn.Linear(in_features, latent_dims)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        loc = self.loc(inputs)\n",
        "        logvar = self.logvar(inputs)\n",
        "        return loc, logvar\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X.view(-1, *self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBeHHO7XRNLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in encoder.named_parameters():\n",
        "    if torch.any(torch.isinf(param) | torch.isnan(param)):\n",
        "        print(name + \" contains inf or nan\")\n",
        "for name, param in decoder.named_parameters():\n",
        "    if torch.any(torch.isinf(param) | torch.isnan(param)):\n",
        "        print(name + \" contains inf or nan\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZDpPBm7Lu9",
        "colab_type": "code",
        "outputId": "539c81e9-8ddd-49cd-d31f-a525511feae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.utils.data\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = encoder = nn.Sequential(OrderedDict([\n",
        "        ('e_conv_layer_1', nn.Conv2d(1, 16, 5, 1)),                # 16 x 24 x 24\n",
        "        ('e_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_1', nn.BatchNorm2d(16)),\n",
        "        ('e_conv_layer_2', nn.Conv2d(16, 32, 5, 1)),               # 32 x 20 x 20\n",
        "        ('e_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_2', nn.BatchNorm2d(32)),\n",
        "        ('e_conv_layer_3', nn.Conv2d(32, 32, 11, 1)),              # 32 x 10 x 10\n",
        "        ('e_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('e_conv_layer_4', nn.Conv2d(32, 64, 5, 1)),               # 64 x 6 x 6\n",
        "        ('e_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_4', nn.BatchNorm2d(64)),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.75)),\n",
        "        ('e_conv_layer_5', nn.Conv2d(64, 128, 5, 1)),              # 128 x 2 x 2\n",
        "        ('e_relu_layer_5', nn.LeakyReLU(inplace=True)),\n",
        "        ('e_batch_norm_5', nn.BatchNorm2d(128)),\n",
        "        ('e_dropout_layer_1', nn.Dropout2d(p=0.85)),\n",
        "        ('e_flatten_layer', nn.Flatten()),\n",
        "        ('e_out_layer', LocLogvar(128*2*2, latent_dims))\n",
        "        ]))\n",
        "\n",
        "        self.decoder = decoder = nn.Sequential(OrderedDict([\n",
        "        ('inv_linear_layer_1', nn.Linear(latent_dims, 128*2*2)),   # 128 * 2 * 2\n",
        "        ('inv_relu_layer_5', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_flatten_layer', Reshape(128, 2, 2)),                 # 128 x 2 x 2\n",
        "        ('inv_conv_layer_5', nn.ConvTranspose2d(128, 64, 5, 1)),   # 64 x 6 x 6\n",
        "        ('inv_batch_norm_5', nn.BatchNorm2d(64)),\n",
        "        ('inv_relu_layer_4', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_4', nn.ConvTranspose2d(64, 32, 5, 1)),    # 32 x 10 x 10\n",
        "        ('inv_batch_norm_4', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_3', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_3', nn.ConvTranspose2d(32, 32, 11, 1)),   # 32 x 20 x 20\n",
        "        ('inv_batch_norm_3', nn.BatchNorm2d(32)),\n",
        "        ('inv_relu_layer_2', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_2', nn.ConvTranspose2d(32, 16, 5, 1)),    # 16 x 24 x 24\n",
        "        ('inv_batch_norm_2', nn.BatchNorm2d(16)),\n",
        "        ('inv_relu_layer_1', nn.LeakyReLU(inplace=True)),\n",
        "        ('inv_conv_layer_1', nn.ConvTranspose2d(16, 1, 5, 1)),     # 1 x 28 x 28\n",
        "        ('inv_batch_norm_1', nn.BatchNorm2d(1)),\n",
        "        ('inv_out_layer', nn.Sigmoid())\n",
        "        ]))\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                         'reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():\n",
        "        sample = torch.randn(64, 20).to(device)\n",
        "        sample = model.decode(sample).cpu()\n",
        "        save_image(sample.view(64, 1, 28, 28),\n",
        "                    'sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 670.281750\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 495.561844\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 490.651344\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 487.086094\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 482.307969\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 481.260344\n",
            "====> Epoch: 1 Average loss: 493.1593\n",
            "====> Test set loss: 451.9796\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 473.426781\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 473.108719\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 468.334063\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 466.814625\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 460.056938\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 452.170062\n",
            "====> Epoch: 2 Average loss: 464.1728\n",
            "====> Test set loss: 438.2047\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 447.521000\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 442.417781\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 438.631719\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 431.983031\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 427.366906\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 420.612406\n",
            "====> Epoch: 3 Average loss: 432.7678\n",
            "====> Test set loss: 398.1583\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 417.667062\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 412.126688\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 406.682594\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 400.146813\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 394.771687\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 390.510781\n",
            "====> Epoch: 4 Average loss: 400.8787\n",
            "====> Test set loss: 373.0727\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 388.991375\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 380.006562\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 376.931188\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 372.261781\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 370.369937\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 364.372937\n",
            "====> Epoch: 5 Average loss: 373.8396\n",
            "====> Test set loss: 350.4906\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 361.650594\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 358.489250\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 355.570500\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 352.656781\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 348.461219\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 346.060187\n",
            "====> Epoch: 6 Average loss: 351.5052\n",
            "====> Test set loss: 334.8710\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 340.376219\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 338.206531\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 336.836531\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 332.508281\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 330.424875\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 327.814813\n",
            "====> Epoch: 7 Average loss: 333.1353\n",
            "====> Test set loss: 316.9294\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 323.428781\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 323.139719\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 318.874000\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 317.416219\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 314.004906\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 311.755656\n",
            "====> Epoch: 8 Average loss: 317.6534\n",
            "====> Test set loss: 304.4527\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 310.559094\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 308.165813\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 305.872063\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 302.374594\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 300.275812\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 298.394281\n",
            "====> Epoch: 9 Average loss: 303.6579\n",
            "====> Test set loss: 292.7852\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 295.524094\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 294.132531\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 293.690375\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 293.824437\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 288.320063\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 285.436844\n",
            "====> Epoch: 10 Average loss: 291.4724\n",
            "====> Test set loss: 276.8388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLMMZtgtEz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a3c91a22-cfb8-4eab-fb78-fd757c231dd1"
      },
      "source": [
        "with torch.no_grad():\n",
        "    sample = torch.randn(1, latent_dims).to(device)\n",
        "    sample = model.decode(sample).cpu()\n",
        "plt.imshow(sample[0, 0, ...])\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzPtSlKcjcgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "#   5. NST   #\n",
        "##############"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}